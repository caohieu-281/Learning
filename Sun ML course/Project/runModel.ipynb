{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a444fbc70dcd>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['setType'][np.isnan(df.label)] = 'test'\n"
     ]
    }
   ],
   "source": [
    "dfTrain = pd.read_csv('train.tsv',sep = '\\t')\n",
    "dfTest = pd.read_csv('test.tsv', sep = '\\t')\n",
    "\n",
    "df = dfTrain.append(dfTest,ignore_index=True)\n",
    "\n",
    "df['setType'] = 'training'\n",
    "df['setType'][np.isnan(df.label)] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "      <th>setType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.popsci.com/technology/article/2012-...</td>\n",
       "      <td>8471</td>\n",
       "      <td>{\"title\":\"The Fully Electronic Futuristic Star...</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.menshealth.com/health/flu-fighting-...</td>\n",
       "      <td>1164</td>\n",
       "      <td>{\"title\":\"Fruits that Fight the Flu fruits tha...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2240</td>\n",
       "      <td>258</td>\n",
       "      <td>11</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.dumblittleman.com/2007/12/10-foolpr...</td>\n",
       "      <td>6684</td>\n",
       "      <td>{\"title\":\"10 Foolproof Tips for Better Sleep \"...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2737</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bleacherreport.com/articles/1205138-the...</td>\n",
       "      <td>9006</td>\n",
       "      <td>{\"title\":\"The 50 Coolest Jerseys You Didn t Kn...</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12032</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10561</th>\n",
       "      <td>http://busy-mommy.com/2012/02/peep-brownie-smo...</td>\n",
       "      <td>7264</td>\n",
       "      <td>{\"title\":\"Peep Brownie S mores Busy Mommy An I...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2772</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.063401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10562</th>\n",
       "      <td>http://www.cannabissearch.com/edibles/cheesecake/</td>\n",
       "      <td>9714</td>\n",
       "      <td>{\"url\":\"cannabissearch edibles cheesecake\",\"ti...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1.305556</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6058</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.061995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10563</th>\n",
       "      <td>http://www.tastespotting.com/popular/views/all...</td>\n",
       "      <td>5903</td>\n",
       "      <td>{\"title\":\"Most Viewed Submissions All Time mos...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.717277</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.182292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2876</td>\n",
       "      <td>192</td>\n",
       "      <td>4</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10564</th>\n",
       "      <td>http://lifehacker.com/5839197/how-to-get-a-ful...</td>\n",
       "      <td>3176</td>\n",
       "      <td>{\"title\":\"How to Get a Complete Workout with N...</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.424304</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21029</td>\n",
       "      <td>180</td>\n",
       "      <td>12</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>http://www.howsweeteats.com/2011/03/crispy-par...</td>\n",
       "      <td>7441</td>\n",
       "      <td>{\"title\":\"Crispy Parmesan Asparagus Sticks How...</td>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.585166</td>\n",
       "      <td>2.621212</td>\n",
       "      <td>0.516373</td>\n",
       "      <td>0.105793</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>13067</td>\n",
       "      <td>397</td>\n",
       "      <td>4</td>\n",
       "      <td>0.287154</td>\n",
       "      <td>0.130024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10566 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  urlid  \\\n",
       "0      http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "1      http://www.popsci.com/technology/article/2012-...   8471   \n",
       "2      http://www.menshealth.com/health/flu-fighting-...   1164   \n",
       "3      http://www.dumblittleman.com/2007/12/10-foolpr...   6684   \n",
       "4      http://bleacherreport.com/articles/1205138-the...   9006   \n",
       "...                                                  ...    ...   \n",
       "10561  http://busy-mommy.com/2012/02/peep-brownie-smo...   7264   \n",
       "10562  http://www.cannabissearch.com/edibles/cheesecake/   9714   \n",
       "10563  http://www.tastespotting.com/popular/views/all...   5903   \n",
       "10564  http://lifehacker.com/5839197/how-to-get-a-ful...   3176   \n",
       "10565  http://www.howsweeteats.com/2011/03/crispy-par...   7441   \n",
       "\n",
       "                                             boilerplate    alchemy_category  \\\n",
       "0      {\"title\":\"IBM Sees Holographic Calls Air Breat...            business   \n",
       "1      {\"title\":\"The Fully Electronic Futuristic Star...          recreation   \n",
       "2      {\"title\":\"Fruits that Fight the Flu fruits tha...              health   \n",
       "3      {\"title\":\"10 Foolproof Tips for Better Sleep \"...              health   \n",
       "4      {\"title\":\"The 50 Coolest Jerseys You Didn t Kn...              sports   \n",
       "...                                                  ...                 ...   \n",
       "10561  {\"title\":\"Peep Brownie S mores Busy Mommy An I...                   ?   \n",
       "10562  {\"url\":\"cannabissearch edibles cheesecake\",\"ti...                   ?   \n",
       "10563  {\"title\":\"Most Viewed Submissions All Time mos...                   ?   \n",
       "10564  {\"title\":\"How to Get a Complete Workout with N...              sports   \n",
       "10565  {\"title\":\"Crispy Parmesan Asparagus Sticks How...  arts_entertainment   \n",
       "\n",
       "      alchemy_category_score  avglinksize  commonlinkratio_1  \\\n",
       "0                   0.789131     2.055556           0.676471   \n",
       "1                   0.574147     3.677966           0.508021   \n",
       "2                   0.996526     2.382883           0.562016   \n",
       "3                   0.801248     1.543103           0.400000   \n",
       "4                   0.719157     2.676471           0.500000   \n",
       "...                      ...          ...                ...   \n",
       "10561                      ?     1.666667           0.376623   \n",
       "10562                      ?     1.305556           0.654321   \n",
       "10563                      ?     0.717277           0.291667   \n",
       "10564               0.424304     0.940000           0.183333   \n",
       "10565               0.585166     2.621212           0.516373   \n",
       "\n",
       "       commonlinkratio_2  commonlinkratio_3  commonlinkratio_4  ...  \\\n",
       "0               0.205882           0.047059           0.023529  ...   \n",
       "1               0.288770           0.213904           0.144385  ...   \n",
       "2               0.321705           0.120155           0.042636  ...   \n",
       "3               0.100000           0.016667           0.000000  ...   \n",
       "4               0.222222           0.123457           0.043210  ...   \n",
       "...                  ...                ...                ...  ...   \n",
       "10561           0.129870           0.116883           0.090909  ...   \n",
       "10562           0.123457           0.024691           0.000000  ...   \n",
       "10563           0.182292           0.000000           0.000000  ...   \n",
       "10564           0.066667           0.016667           0.016667  ...   \n",
       "10565           0.105793           0.015113           0.002519  ...   \n",
       "\n",
       "       lengthyLinkDomain  linkwordscore  news_front_page  \\\n",
       "0                      1             24                0   \n",
       "1                      1             40                0   \n",
       "2                      1             55                0   \n",
       "3                      0             24                0   \n",
       "4                      1             14                0   \n",
       "...                  ...            ...              ...   \n",
       "10561                  0             16                0   \n",
       "10562                  0              6                0   \n",
       "10563                  0             19                0   \n",
       "10564                  1              3                0   \n",
       "10565                  1             14                0   \n",
       "\n",
       "       non_markup_alphanum_characters  numberOfLinks  numwords_in_url  \\\n",
       "0                                5424            170                8   \n",
       "1                                4973            187                9   \n",
       "2                                2240            258               11   \n",
       "3                                2737            120                5   \n",
       "4                               12032            162               10   \n",
       "...                               ...            ...              ...   \n",
       "10561                            2772             77                3   \n",
       "10562                            6058             81                2   \n",
       "10563                            2876            192                4   \n",
       "10564                           21029            180               12   \n",
       "10565                           13067            397                4   \n",
       "\n",
       "       parametrizedLinkRatio spelling_errors_ratio  label   setType  \n",
       "0                   0.152941              0.079130    0.0  training  \n",
       "1                   0.181818              0.125448    1.0  training  \n",
       "2                   0.166667              0.057613    1.0  training  \n",
       "3                   0.041667              0.100858    1.0  training  \n",
       "4                   0.098765              0.082569    0.0  training  \n",
       "...                      ...                   ...    ...       ...  \n",
       "10561               0.012987              0.063401    NaN      test  \n",
       "10562               0.333333              0.061995    NaN      test  \n",
       "10563               0.177083              0.117647    NaN      test  \n",
       "10564               0.333333              0.111966    NaN      test  \n",
       "10565               0.287154              0.130024    NaN      test  \n",
       "\n",
       "[10566 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBoilerPlateText(text, obj = 'title'):    \n",
    "    try:\n",
    "        result = json.loads(text)[obj].encode('utf-8').strip()    \n",
    "    except:  # if there is no title, put in blank\n",
    "        result = ''\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boilerPlateTitles = df.boilerplate.apply(getBoilerPlateText,obj = 'title')\n",
    "boilerPlateBodies = df.boilerplate.apply(getBoilerPlateText,obj =  'body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     b'IBM Sees Holographic Calls Air Breathing Bat...\n",
       "1     b'The Fully Electronic Futuristic Starting Gun...\n",
       "2     b\"Fruits that Fight the Flu fruits that fight ...\n",
       "3                 b'10 Foolproof Tips for Better Sleep'\n",
       "4     b\"The 50 Coolest Jerseys You Didn t Know Exist...\n",
       "5                           b'Genital Herpes Treatment'\n",
       "6                   b'fashion lane American Wild Child'\n",
       "7     b'Racing For Recovery by Dean Johnson racing f...\n",
       "8                 b'Valet The Handbook 31 Days 31 days'\n",
       "9         b'Cookies and Cream Brownies How Sweet It Is'\n",
       "10    b'Business Financial News Breaking US Internat...\n",
       "11    b'A Tip of the Cap to The Greatest Iron Man of...\n",
       "12                     b'9 Foods That Trash Your Teeth'\n",
       "13                                                  b''\n",
       "14    b'French Onion Steaks with Red Wine Sauce fren...\n",
       "15    b'Izabel Goulart Swimsuit by Kikidoll 2012 Spo...\n",
       "16                b'Liquid Mountaineering The Awesomer'\n",
       "17                                                     \n",
       "18                      b'Grilled Peaches Sugarcrafter'\n",
       "19    b'How to Make Your Home Healthier A Room by Ro...\n",
       "Name: boilerplate, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boilerPlateTitles.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     b'A sign stands outside the International Busi...\n",
       "1     b'And that can be carried on a plane without t...\n",
       "2     b'Apples The most popular source of antioxidan...\n",
       "3     b'There was a period in my life when I had a l...\n",
       "4     b\"Jersey sales is a curious business Whether y...\n",
       "5     b'Genital herpes is caused by herpes simplex v...\n",
       "6     b'Our favorite summer holiday is just around t...\n",
       "7     b'Racing For Recovery is the growing idea that...\n",
       "8     b\"Resolutions are for suckers Instead of swear...\n",
       "9     b\"More brownies It seems that I can t get thro...\n",
       "10    b'Faced with a stream of financial scandals th...\n",
       "11    b\"As you surely know by now Brett Favre s NFL ...\n",
       "12    b'There are the 700 different types of germs i...\n",
       "13                                                  b''\n",
       "14    b'Really this is just an excuse to get drunk O...\n",
       "15    b'TM 2012 Turner Broadcasting System Inc A Tim...\n",
       "16    b\"Link We re pretty skeptical about walking on...\n",
       "17    b'The annual Chap Olympiad described as a cele...\n",
       "18    b'June 6 2011 Print E mail Filed under grilled...\n",
       "19    b\"Studies show one in three shower heads are c...\n",
       "Name: boilerplate, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boilerPlateBodies.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Vectorizer will by default remove punctuation and convert to lower case. We just need to strip the stop words before training our classifier.\n",
    "vectorizer = TfidfVectorizer(min_df=2,stop_words='english',binary=False, analyzer='word', use_idf = True, smooth_idf = True, sublinear_tf = True) # use binary option to check for instances instead of summing instances\n",
    "bodyVect = vectorizer.fit_transform(boilerPlateBodies)\n",
    "titleVect = vectorizer.fit_transform(boilerPlateTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10566x45345 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1461233 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countText(text, pattern, relative = True):\n",
    "    import re\n",
    "    result = len(re.findall(pattern, text))\n",
    "    if relative == True:\n",
    "        result = result / np.double(countWords(text))\n",
    "    if text == '':\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWords(text):\n",
    "    import nltk\n",
    "    if text == '':\n",
    "        result = 0\n",
    "    else: \n",
    "        result = len(nltk.word_tokenize(text))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyTerms = ['\\,',\n",
    "            '\\!',\n",
    "            'butter',\n",
    "            'water',\n",
    "            'cup',\n",
    "            'degree',\n",
    "            'recipe'\n",
    "            'comment',\n",
    "            'email',\n",
    "            'contact',\n",
    "            '[0-9]{4}',\n",
    "            '\\|',\n",
    "            '\\d',\n",
    "            '@',\n",
    "            'calories',\n",
    "            'sign?in',\n",
    "            'log?in',\n",
    "            'register'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "boilerPlateBodies.apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ddb459c89bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtextFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeyTerms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtextFeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bpBodyContains_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboilerPlateBodies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtextFeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bpTitleContains_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboilerPlateTitles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   4183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-c5e524a3eb9c>\u001b[0m in \u001b[0;36mcountText\u001b[0;34m(text, pattern, relative)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcountText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountWords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "textFeatures = pd.DataFrame(index = df.index)\n",
    "for term in keyTerms:\n",
    "    textFeatures['bpBodyContains_' + term] = boilerPlateBodies.apply(countText, pattern = term, relative = True)\n",
    "    textFeatures['bpTitleContains_' + term] = boilerPlateTitles.apply(countText, pattern = term, relative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrlDomain(url):\n",
    "    import urlparse\n",
    "    import re\n",
    "    parsed = urlparse.urlparse(url)\n",
    "    domain = re.sub('^www\\.', '', parsed.netloc).split('.')\n",
    "    result = domain[len(domain)-1]\n",
    "    return result\n",
    "\n",
    "def getName(url):\n",
    "    import urlparse\n",
    "    import re\n",
    "    parsed = urlparse.urlparse(url)\n",
    "    domain = re.sub('^www\\.', '', parsed.netloc).split('.')\n",
    "    result = domain[0]\n",
    "    return result\n",
    "\n",
    "def countPaths(url):\n",
    "    import urlparse\n",
    "    import re\n",
    "    parsed = urlparse.urlparse(url)\n",
    "    domain = re.findall('\\/',parsed.path)\n",
    "    return len(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = df.url.apply(getUrlDomain)\n",
    "webNames = df.url.apply(getName)\n",
    "numPaths = df.url.apply(countPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_df = pd.get_dummies(domains, prefix = 'DUM')\n",
    "webNames_df = pd.get_dummies(webNames, prefix = 'DUM')\n",
    "alchemyCategories_df = pd.get_dummies(df.alchemy_category, prefix = 'DUM')\n",
    "numPaths_df = pd.get_dummies(numPaths, prefix = 'DUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalFeatureList =['avglinksize','commonlinkratio_1','commonlinkratio_2','commonlinkratio_3','commonlinkratio_4', \n",
    "           'compression_ratio','embed_ratio','frameTagRatio', 'framebased', 'hasDomainLink', 'html_ratio', 'image_ratio', \n",
    "           'is_news', 'lengthyLinkDomain', 'linkwordscore', 'news_front_page', 'non_markup_alphanum_characters', 'numberOfLinks',\n",
    "           'numwords_in_url', 'parametrizedLinkRatio', 'spelling_errors_ratio']\n",
    "\n",
    "originalFeatures = df[originalFeatureList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "titleDecomposed = TruncatedSVD(random_state = 123, n_components = 10).fit_transform(titleVect)\n",
    "bodyDecomposed = TruncatedSVD(random_state = 123, n_components = 50).fit_transform(bodyVect)\n",
    "\n",
    "textDecomposed = np.hstack([titleDecomposed,bodyDecomposed])\n",
    "textDecomposed_training = textDecomposed[df.setType == 'training']\n",
    "textDecomposed_test = textDecomposed[df.setType == 'test']\n",
    "\n",
    "\n",
    "# used for estimating alch cats\n",
    "titleDecomposed2 = TruncatedSVD(random_state = 123, n_components = 100).fit_transform(titleVect)\n",
    "bodyDecomposed2 = TruncatedSVD(random_state = 123, n_components = 500).fit_transform(bodyVect)\n",
    "textDecomposed2 = np.hstack([titleDecomposed2,bodyDecomposed2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Training and Test Data\n",
    "originalFeatures_training = originalFeatures[df.setType == 'training']\n",
    "textFeatures_training = textFeatures[df.setType == 'training']\n",
    "domains_training = domains_df[df.setType == 'training']\n",
    "webNames_training = webNames_df[df.setType == 'training']\n",
    "numPaths_training = numPaths_df[df.setType == 'training']\n",
    "alchemyCategories_training = alchemyCategories_df[df.setType == 'training']\n",
    "\n",
    "Y = df[df.setType == 'training'].label\n",
    "X = np.concatenate((originalFeatures_training.values, textFeatures_training, numPaths_training,\n",
    "                    domains_training.values, webNames_training.values,alchemyCategories_training.values), 1)\n",
    "X[X == '?'] = 0\n",
    "\n",
    "\n",
    "# Construct ALTERNATE Training and Test Data\n",
    "X_alt = np.hstack([X, textDecomposed_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalFeatures_test = originalFeatures[df.setType == 'test']\n",
    "textFeatures_test = textFeatures[df.setType == 'test']\n",
    "domains_test = domains_df[df.setType == 'test']\n",
    "webNames_test = webNames_df[df.setType == 'test']\n",
    "numPaths_test = numPaths_df[df.setType == 'test']\n",
    "alchemyCategories_test = alchemyCategories_df[df.setType == 'test']\n",
    "\n",
    "X_Test = np.concatenate((originalFeatures_test.values, textFeatures_test, numPaths_test,\n",
    "                    domains_test.values, webNames_test.values,alchemyCategories_test.values), 1)\n",
    "X_Test[X_Test == '?'] = 0\n",
    "\n",
    "X_Test_alt = np.hstack([X_Test, textDecomposed_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(df[df.setType == 'test'].urlid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossVal(clf, X_data, Y_data, NFOLDS = 10): \n",
    "    import sklearn.ensemble as ens\n",
    "    from sklearn import metrics\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "    skf = StratifiedKFold(Y_data, n_folds = NFOLDS)\n",
    "    auc = []\n",
    "    for train_index, test_index in skf:\n",
    "        x_train, x_test = X_data[train_index], X_data[test_index]\n",
    "        y_train, y_test = Y_data[train_index], Y_data[test_index]\n",
    "        \n",
    "        clf.fit(x_train, y_train)\n",
    "        \n",
    "        try: \n",
    "            probs = clf.predict_proba(x_test)\n",
    "            y_hat = probs[:,1]\n",
    "        except:\n",
    "            y_hat = clf.predict(x_test)\n",
    "        auc.append(metrics.roc_auc_score(y_test, y_hat))\n",
    "    print auc\n",
    "    print np.mean(auc)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,\n",
       "       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=1000,\n",
       "       n_alphas=100, n_jobs=1, normalize=False, precompute='auto',\n",
       "       tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticCV = ElasticNetCV(l1_ratio= [.1, .5, .7, .9, .95, .99, 1], n_jobs = 2)\n",
    "elasticCV.fit(X.astype(np.float),Y)\n",
    "alpha_star = elasticCV.alpha_\n",
    "l1_ratio_star = elasticCV.l1_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.589482653704\n",
      "rho: 0.1\n",
      "[0.62111842105263071, 0.6539254385964911, 0.62657163742690059, 0.64047514619882906, 0.59868421052631571, 0.62637056581647621, 0.62775579009088234, 0.65041776605101154, 0.57822486074464952, 0.6257147045887701]\n"
     ]
    }
   ],
   "source": [
    "# l1: 0.8, alpha = 1\n",
    "\n",
    "clf_EN_1 = ElasticNet(alpha = alpha_star, l1_ratio=l1_ratio_star)\n",
    "results = crossVal(clf_EN_1,X.astype(np.float),Y,10)\n",
    "print 'alpha: ' + str(alpha_star)\n",
    "print 'rho: ' + str(l1_ratio_star)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion = 'gini',random_state = 123,\n",
    "                                 min_samples_leaf = 2, min_samples_split = 6, n_estimators = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =  LogisticRegression(random_state = 123, penalty = 'l1', C = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a5e2a2773c97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_alt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprobs_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Test_alt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprobs_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfinalPrediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprobs_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinalPrediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alt' is not defined"
     ]
    }
   ],
   "source": [
    "rf.fit(X_alt, Y)\n",
    "lr.fit(X_alt, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_rf = rf.predict_proba(X_Test_alt)[:,1]\n",
    "probs_lr = lr.predict_proba(X_Test_alt.astype(np.float))[:,1]\n",
    "finalPrediction = np.vstack([probs_rf, probs_lr]).mean(0)\n",
    "submission['label'] = finalPrediction.T\n",
    "submission.to_csv('submission_21.csv', index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train chosen classifier and predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPrediction = np.vstack([y_hat_GBM, y_hat_RF]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86701754385964902, 0.85896929824561297, 0.88310672514619903, 0.87345760233918102, 0.86160818713450316, 0.89448841981823568, 0.86003371445323962, 0.87238346525945376, 0.8564057461155089, 0.85340126081219814]\n",
      "0.868087196318\n"
     ]
    }
   ],
   "source": [
    "print RF_Best_alt_cv\n",
    "print np.mean(RF_Best_alt_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters3 = {'learning_rate': [0.05, 0.1, 0.25, 0.5, 0.75],\n",
    "              'n_estimators' : [100, 300, 500, 700, 1000, 2000, 4000],\n",
    "              'max_depth' : [2,3,4,5,10,15,20,50,100],\n",
    "              'min_samples_split' : [2,4,6,8,10],\n",
    "              'min_samples_leaf' : [1,2,5],\n",
    "              'subsample' : [0.5, 0.75, 1]}\n",
    "clfGBMGrid = GridSearchCV(GradientBoostingClassifier(random_state = 123), parameters3).fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 123, penalty = 'l1', C = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86211257309941691, 0.8669809941520461, 0.88327485380117032, 0.88035087719298522, 0.85097953216374278, 0.88353855174435636, 0.86282615068894819, 0.877814423922603, 0.84919378481383645, 0.85499193666617901]\n",
      "0.867206367825\n"
     ]
    }
   ],
   "source": [
    "results = crossVal(lr, X_alt.astype(np.float), Y, 10)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_rf = AdaBoostClassifier(base_estimator=rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87054824561403465, 0.8634429824561427, 0.88392543859649209, 0.87408625730994072, 0.86663742690058687, 0.89635004397537366, 0.86713573732043414, 0.87586484901788386, 0.85677953679273, 0.85437619117431451]\n",
      "0.870914670916\n"
     ]
    }
   ],
   "source": [
    "results = crossVal(ada_rf, X_alt, Y)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alch_cat_training = df[(df.alchemy_category != '?') & (df.alchemy_category != 'unknown') & (df.setType == 'training')].alchemy_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = textDecomposed2[(df.alchemy_category != '?') & (df.alchemy_category != 'unknown') & (df.setType == 'training')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "alch_cats = alch_cat_training.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for item in alch_cats:\n",
    "    alch_cat_training[alch_cat_training == item] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    business  recreation  health  sports  arts_entertainment  \\\n",
      "business                 482         159      37      10                  83   \n",
      "recreation               209         680      37      36                 118   \n",
      "health                    26          18     385       6                  19   \n",
      "sports                    12          15      13     280                  28   \n",
      "arts_entertainment       141         121      27      62                 473   \n",
      "science_technology        47          27      28       3                  24   \n",
      "gaming                     8          10       6      12                  12   \n",
      "culture_politics          36          60      17       8                  43   \n",
      "computer_internet         14          39       6       3                  28   \n",
      "law_crime                  5           3       0       0                   7   \n",
      "religion                   9           8       8       3                  16   \n",
      "weather                    0           0       0       0                   1   \n",
      "\n",
      "                    science_technology  gaming  culture_politics  \\\n",
      "business                            30       1                15   \n",
      "recreation                          27       1                32   \n",
      "health                              14       0                12   \n",
      "sports                               5       0                10   \n",
      "arts_entertainment                  14       2                33   \n",
      "science_technology                 126       0                 9   \n",
      "gaming                               0      13                 1   \n",
      "culture_politics                    10       0               146   \n",
      "computer_internet                    9       0                 4   \n",
      "law_crime                            0       0                 2   \n",
      "religion                             3       0                 5   \n",
      "weather                              0       0                 0   \n",
      "\n",
      "                    computer_internet  law_crime  religion  weather  \n",
      "business                           29          0         1       33  \n",
      "recreation                         28          0         1       60  \n",
      "health                              5          0         0       21  \n",
      "sports                              2          0         1       14  \n",
      "arts_entertainment                 23          0         2       43  \n",
      "science_technology                 11          0         0       14  \n",
      "gaming                              5          0         0        9  \n",
      "culture_politics                    7          1         0       15  \n",
      "computer_internet                 178          0         1       14  \n",
      "law_crime                           0         11         0        3  \n",
      "religion                            1          0        12        7  \n",
      "weather                             0          0         0        3  \n"
     ]
    }
   ],
   "source": [
    "clf2 = BernoulliNB(alpha = 0.5, fit_prior=True)\n",
    "clf2.fit(predictors, alch_cat_training.astype(np.int))\n",
    "predicted = clf2.predict(predictors)\n",
    "result = pd.DataFrame(confusion_matrix(alch_cat_training.astype(np.int), predicted), columns = alch_cats, index = alch_cats)\n",
    "print result\n",
    "estAlchCat = clf2.predict(textDecomposed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "estAlchCat[(df.alchemy_category != '?') & (df.alchemy_category != 'unknown') & (df.setType == 'training')] = alch_cat_training[(df.alchemy_category != '?') & (df.alchemy_category != 'unknown') & (df.setType == 'training')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "alchemyCategories2_df = pd.get_dummies(estAlchCat, prefix = 'DUM')\n",
    "alchemyCategories2_training = alchemyCategories2_df[df.setType == 'training']\n",
    "alchemyCategories2_test = alchemyCategories2_df[df.setType == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alt_2 = X = np.hstack([originalFeatures_training.values, textFeatures_training, numPaths_training,\n",
    "                    domains_training.values, webNames_training.values,alchemyCategories2_training.values, textDecomposed_training])\n",
    "\n",
    "X_Test_2 = np.hstack([originalFeatures_test.values, textFeatures_test, numPaths_test,\n",
    "                    domains_test.values, webNames_test.values,alchemyCategories2_test.values, textDecomposed_test])\n",
    "\n",
    "X_alt_2[X_alt_2 == '?'] = 0\n",
    "X_Test_2[X_Test_2 == '?'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86582602339181425, 0.86538011695906492, 0.88462719298245562, 0.87537280701754439, 0.86476608187134452, 0.89866608032834916, 0.86748021108179463, 0.87712547639988148, 0.85537965406039185, 0.85117284855592923]\n",
      "0.870579649265\n"
     ]
    }
   ],
   "source": [
    "results = crossVal(rf, X_alt_2, Y)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86722953216374221, 0.86760964912280591, 0.88595760233918197, 0.87606725146198894, 0.85593567251462133, 0.88792143066549356, 0.86999413661682912, 0.87944151275285798, 0.85029316915860287, 0.85405365782143294]\n",
      "0.869450361462\n"
     ]
    }
   ],
   "source": [
    "results = crossVal(lr, X_alt_2.astype(np.float), Y)\n",
    "print results\n",
    "print np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86604532163742776, 0.87507309941520584, 0.88288377192982503, 0.8753106725146188, 0.87012792397660765, 0.89775359132219124, 0.87153693931398435, 0.87915200820873529, 0.85851289944297993, 0.85981527635244115]\n",
      "0.873621150411\n"
     ]
    }
   ],
   "source": [
    "results = crossVal(gbm, X_alt_2, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86722953216374221, 0.86760964912280591, 0.88595760233918197, 0.87606725146198894, 0.85593567251462133, 0.88792143066549356, 0.86999413661682912, 0.87944151275285798, 0.85029316915860287, 0.85405365782143294]\n",
      "0.869450361462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.86722953216374221,\n",
       " 0.86760964912280591,\n",
       " 0.88595760233918197,\n",
       " 0.87606725146198894,\n",
       " 0.85593567251462133,\n",
       " 0.88792143066549356,\n",
       " 0.86999413661682912,\n",
       " 0.87944151275285798,\n",
       " 0.85029316915860287,\n",
       " 0.85405365782143294]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossVal(lr, X_alt_2.astype(np.float), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "gbm_parameters = {'n_estimators':[20, 50,100,200,500,1000]}\n",
    "gbm = GradientBoostingClassifier(random_state = 123, max_depth = 6)\n",
    "gbm_grid = GridSearchCV(gbm, gbm_parameters, verbose = 1, n_jobs = 4).fit(X_alt_2,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
