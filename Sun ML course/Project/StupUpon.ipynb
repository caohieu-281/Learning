{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, roc_auc_score\n",
    "\n",
    "\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize.punkt import PunktToken\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import lda\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>is_news</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.popsci.com/technology/article/2012-...</td>\n",
       "      <td>8471</td>\n",
       "      <td>{\"title\":\"The Fully Electronic Futuristic Star...</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4973</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.menshealth.com/health/flu-fighting-...</td>\n",
       "      <td>1164</td>\n",
       "      <td>{\"title\":\"Fruits that Fight the Flu fruits tha...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2240</td>\n",
       "      <td>258</td>\n",
       "      <td>11</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.dumblittleman.com/2007/12/10-foolpr...</td>\n",
       "      <td>6684</td>\n",
       "      <td>{\"title\":\"10 Foolproof Tips for Better Sleep \"...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2737</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bleacherreport.com/articles/1205138-the...</td>\n",
       "      <td>9006</td>\n",
       "      <td>{\"title\":\"The 50 Coolest Jerseys You Didn t Kn...</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12032</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>http://techcrunch.com/2010/09/08/kno-raises-46...</td>\n",
       "      <td>8958</td>\n",
       "      <td>{\"title\":\"Kno Raises 46 Million More To Build ...</td>\n",
       "      <td>computer_internet</td>\n",
       "      <td>0.651067</td>\n",
       "      <td>3.010526</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2219</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>http://www.uncoached.com/category/why-i-miss-c...</td>\n",
       "      <td>8895</td>\n",
       "      <td>{\"title\":\"Why I Miss College \",\"body\":\"Mar 30 ...</td>\n",
       "      <td>culture_politics</td>\n",
       "      <td>0.14192</td>\n",
       "      <td>2.208054</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5672</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>http://eatthis.menshealth.com/slide/sweet-pota...</td>\n",
       "      <td>1191</td>\n",
       "      <td>{\"title\":\"Sweet Potatoes Eat This Not That  i'...</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.196273</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>848</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>http://naturallyella.com/</td>\n",
       "      <td>5612</td>\n",
       "      <td>{\"title\":\"Naturally Ella \",\"body\":\" \",\"url\":\"n...</td>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>0.617876</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>386</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>http://sportsillustrated.cnn.com/2011_swimsuit...</td>\n",
       "      <td>90</td>\n",
       "      <td>{\"title\":\"Esti Ginzburg Swimsuit by Letarte by...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1.158209</td>\n",
       "      <td>0.505917</td>\n",
       "      <td>0.428994</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>?</td>\n",
       "      <td>515</td>\n",
       "      <td>338</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.134146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7395 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  urlid  \\\n",
       "0     http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "1     http://www.popsci.com/technology/article/2012-...   8471   \n",
       "2     http://www.menshealth.com/health/flu-fighting-...   1164   \n",
       "3     http://www.dumblittleman.com/2007/12/10-foolpr...   6684   \n",
       "4     http://bleacherreport.com/articles/1205138-the...   9006   \n",
       "...                                                 ...    ...   \n",
       "7390  http://techcrunch.com/2010/09/08/kno-raises-46...   8958   \n",
       "7391  http://www.uncoached.com/category/why-i-miss-c...   8895   \n",
       "7392  http://eatthis.menshealth.com/slide/sweet-pota...   1191   \n",
       "7393                          http://naturallyella.com/   5612   \n",
       "7394  http://sportsillustrated.cnn.com/2011_swimsuit...     90   \n",
       "\n",
       "                                            boilerplate    alchemy_category  \\\n",
       "0     {\"title\":\"IBM Sees Holographic Calls Air Breat...            business   \n",
       "1     {\"title\":\"The Fully Electronic Futuristic Star...          recreation   \n",
       "2     {\"title\":\"Fruits that Fight the Flu fruits tha...              health   \n",
       "3     {\"title\":\"10 Foolproof Tips for Better Sleep \"...              health   \n",
       "4     {\"title\":\"The 50 Coolest Jerseys You Didn t Kn...              sports   \n",
       "...                                                 ...                 ...   \n",
       "7390  {\"title\":\"Kno Raises 46 Million More To Build ...   computer_internet   \n",
       "7391  {\"title\":\"Why I Miss College \",\"body\":\"Mar 30 ...    culture_politics   \n",
       "7392  {\"title\":\"Sweet Potatoes Eat This Not That  i'...          recreation   \n",
       "7393  {\"title\":\"Naturally Ella \",\"body\":\" \",\"url\":\"n...  arts_entertainment   \n",
       "7394  {\"title\":\"Esti Ginzburg Swimsuit by Letarte by...                   ?   \n",
       "\n",
       "     alchemy_category_score  avglinksize  commonlinkratio_1  \\\n",
       "0                  0.789131     2.055556           0.676471   \n",
       "1                  0.574147     3.677966           0.508021   \n",
       "2                  0.996526     2.382883           0.562016   \n",
       "3                  0.801248     1.543103           0.400000   \n",
       "4                  0.719157     2.676471           0.500000   \n",
       "...                     ...          ...                ...   \n",
       "7390               0.651067     3.010526           0.474747   \n",
       "7391                0.14192     2.208054           0.483333   \n",
       "7392               0.196273     2.000000           0.315789   \n",
       "7393               0.617876     1.026316           0.210526   \n",
       "7394                      ?     1.158209           0.505917   \n",
       "\n",
       "      commonlinkratio_2  commonlinkratio_3  commonlinkratio_4  ...  is_news  \\\n",
       "0              0.205882           0.047059           0.023529  ...        1   \n",
       "1              0.288770           0.213904           0.144385  ...        1   \n",
       "2              0.321705           0.120155           0.042636  ...        1   \n",
       "3              0.100000           0.016667           0.000000  ...        1   \n",
       "4              0.222222           0.123457           0.043210  ...        1   \n",
       "...                 ...                ...                ...  ...      ...   \n",
       "7390           0.222222           0.191919           0.191919  ...        1   \n",
       "7391           0.246667           0.036667           0.026667  ...        1   \n",
       "7392           0.171053           0.105263           0.052632  ...        ?   \n",
       "7393           0.052632           0.000000           0.000000  ...        1   \n",
       "7394           0.428994           0.023669           0.000000  ...        ?   \n",
       "\n",
       "      lengthyLinkDomain  linkwordscore  news_front_page  \\\n",
       "0                     1             24                0   \n",
       "1                     1             40                0   \n",
       "2                     1             55                0   \n",
       "3                     0             24                0   \n",
       "4                     1             14                0   \n",
       "...                 ...            ...              ...   \n",
       "7390                  1             38                0   \n",
       "7391                  1             34                0   \n",
       "7392                  1             43                0   \n",
       "7393                  0             37                1   \n",
       "7394                  0             78                ?   \n",
       "\n",
       "      non_markup_alphanum_characters  numberOfLinks  numwords_in_url  \\\n",
       "0                               5424            170                8   \n",
       "1                               4973            187                9   \n",
       "2                               2240            258               11   \n",
       "3                               2737            120                5   \n",
       "4                              12032            162               10   \n",
       "...                              ...            ...              ...   \n",
       "7390                            2219             99               11   \n",
       "7391                            5672            300                4   \n",
       "7392                             848             76                5   \n",
       "7393                             386             38                0   \n",
       "7394                             515            338                4   \n",
       "\n",
       "     parametrizedLinkRatio  spelling_errors_ratio  label  \n",
       "0                 0.152941               0.079130      0  \n",
       "1                 0.181818               0.125448      1  \n",
       "2                 0.166667               0.057613      1  \n",
       "3                 0.041667               0.100858      1  \n",
       "4                 0.098765               0.082569      0  \n",
       "...                    ...                    ...    ...  \n",
       "7390              0.040404               0.071429      0  \n",
       "7391              0.020000               0.109453      0  \n",
       "7392              0.434211               0.117647      1  \n",
       "7393              0.026316               0.333333      1  \n",
       "7394              0.005917               0.134146      0  \n",
       "\n",
       "[7395 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.tsv', delimiter='\\t',encoding='utf-8')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_columns(data_):\n",
    "    total_na = data_.isna().sum().sum()\n",
    "    print(\"Dimensional:\", data_.shape[0], \"rows,\", data_.shape[1], \"columns\")\n",
    "    print(\"Total NA values: %d\" %(total_na))\n",
    "    print(\"%38s%10s%10s%10s\" %(\"Column Name\", \"Data type\", \"#Distinct\", \"#NaN\"))\n",
    "    col_name = data_.columns\n",
    "    dtype = data_.dtypes\n",
    "    uniq = data_.nunique()\n",
    "    \n",
    "    for i in range(len(col_name)):\n",
    "        print(\"%38s%10s%10s%10s\" %(col_name[i], dtype[i], uniq[i], data_[col_name[i]].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensional: 7395 rows, 27 columns\n",
      "Total NA values: 0\n",
      "                           Column Name Data type #Distinct      #NaN\n",
      "                                   url    object      7395         0\n",
      "                                 urlid     int64      7395         0\n",
      "                           boilerplate    object      7394         0\n",
      "                      alchemy_category    object        14         0\n",
      "                alchemy_category_score    object      4806         0\n",
      "                           avglinksize   float64      5710         0\n",
      "                     commonlinkratio_1   float64      4476         0\n",
      "                     commonlinkratio_2   float64      4038         0\n",
      "                     commonlinkratio_3   float64      3266         0\n",
      "                     commonlinkratio_4   float64      2695         0\n",
      "                     compression_ratio   float64      6453         0\n",
      "                           embed_ratio   float64       366         0\n",
      "                            framebased     int64         1         0\n",
      "                         frameTagRatio   float64      5911         0\n",
      "                         hasDomainLink     int64         2         0\n",
      "                            html_ratio   float64      7376         0\n",
      "                           image_ratio   float64      5418         0\n",
      "                               is_news    object         2         0\n",
      "                     lengthyLinkDomain     int64         2         0\n",
      "                         linkwordscore     int64       101         0\n",
      "                       news_front_page    object         3         0\n",
      "        non_markup_alphanum_characters     int64      5301         0\n",
      "                         numberOfLinks     int64       702         0\n",
      "                       numwords_in_url     int64        23         0\n",
      "                 parametrizedLinkRatio   float64      3922         0\n",
      "                 spelling_errors_ratio   float64      4219         0\n",
      "                                 label     int64         2         0\n"
     ]
    }
   ],
   "source": [
    "info_columns(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>urlid</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>5305.704665</td>\n",
       "      <td>3048.384114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2688.500000</td>\n",
       "      <td>5304.000000</td>\n",
       "      <td>7946.500000</td>\n",
       "      <td>10566.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avglinksize</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>2.761823</td>\n",
       "      <td>8.619793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.602062</td>\n",
       "      <td>2.088235</td>\n",
       "      <td>2.627451</td>\n",
       "      <td>363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.468230</td>\n",
       "      <td>0.203133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340370</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.616604</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.214080</td>\n",
       "      <td>0.146743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.202454</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.092062</td>\n",
       "      <td>0.095978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.049262</td>\n",
       "      <td>0.072629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.065065</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compression_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>2.255103</td>\n",
       "      <td>5.704313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442616</td>\n",
       "      <td>0.483680</td>\n",
       "      <td>0.578227</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>-0.103750</td>\n",
       "      <td>0.306545</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>framebased</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frameTagRatio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.056423</td>\n",
       "      <td>0.041446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028502</td>\n",
       "      <td>0.045775</td>\n",
       "      <td>0.073459</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasDomainLink</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>0.144162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>html_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.233778</td>\n",
       "      <td>0.052487</td>\n",
       "      <td>0.045564</td>\n",
       "      <td>0.201061</td>\n",
       "      <td>0.230564</td>\n",
       "      <td>0.260770</td>\n",
       "      <td>0.716883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.275709</td>\n",
       "      <td>1.919320</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.083051</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>113.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.660311</td>\n",
       "      <td>0.473636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linkwordscore</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>30.077079</td>\n",
       "      <td>20.393101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>5716.598242</td>\n",
       "      <td>8875.432430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>6377.000000</td>\n",
       "      <td>207952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numberOfLinks</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>178.754564</td>\n",
       "      <td>179.466198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>4997.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numwords_in_url</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>4.960649</td>\n",
       "      <td>3.233111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.172864</td>\n",
       "      <td>0.183286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.241299</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.101221</td>\n",
       "      <td>0.079231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068739</td>\n",
       "      <td>0.089312</td>\n",
       "      <td>0.112376</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.513320</td>\n",
       "      <td>0.499856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count         mean          std       min  \\\n",
       "urlid                           7395.0  5305.704665  3048.384114  1.000000   \n",
       "avglinksize                     7395.0     2.761823     8.619793  0.000000   \n",
       "commonlinkratio_1               7395.0     0.468230     0.203133  0.000000   \n",
       "commonlinkratio_2               7395.0     0.214080     0.146743  0.000000   \n",
       "commonlinkratio_3               7395.0     0.092062     0.095978  0.000000   \n",
       "commonlinkratio_4               7395.0     0.049262     0.072629  0.000000   \n",
       "compression_ratio               7395.0     2.255103     5.704313  0.000000   \n",
       "embed_ratio                     7395.0    -0.103750     0.306545 -1.000000   \n",
       "framebased                      7395.0     0.000000     0.000000  0.000000   \n",
       "frameTagRatio                   7395.0     0.056423     0.041446  0.000000   \n",
       "hasDomainLink                   7395.0     0.021231     0.144162  0.000000   \n",
       "html_ratio                      7395.0     0.233778     0.052487  0.045564   \n",
       "image_ratio                     7395.0     0.275709     1.919320 -1.000000   \n",
       "lengthyLinkDomain               7395.0     0.660311     0.473636  0.000000   \n",
       "linkwordscore                   7395.0    30.077079    20.393101  0.000000   \n",
       "non_markup_alphanum_characters  7395.0  5716.598242  8875.432430  0.000000   \n",
       "numberOfLinks                   7395.0   178.754564   179.466198  1.000000   \n",
       "numwords_in_url                 7395.0     4.960649     3.233111  0.000000   \n",
       "parametrizedLinkRatio           7395.0     0.172864     0.183286  0.000000   \n",
       "spelling_errors_ratio           7395.0     0.101221     0.079231  0.000000   \n",
       "label                           7395.0     0.513320     0.499856  0.000000   \n",
       "\n",
       "                                        25%          50%          75%  \\\n",
       "urlid                           2688.500000  5304.000000  7946.500000   \n",
       "avglinksize                        1.602062     2.088235     2.627451   \n",
       "commonlinkratio_1                  0.340370     0.481481     0.616604   \n",
       "commonlinkratio_2                  0.105263     0.202454     0.300000   \n",
       "commonlinkratio_3                  0.022222     0.068627     0.133333   \n",
       "commonlinkratio_4                  0.000000     0.022222     0.065065   \n",
       "compression_ratio                  0.442616     0.483680     0.578227   \n",
       "embed_ratio                        0.000000     0.000000     0.000000   \n",
       "framebased                         0.000000     0.000000     0.000000   \n",
       "frameTagRatio                      0.028502     0.045775     0.073459   \n",
       "hasDomainLink                      0.000000     0.000000     0.000000   \n",
       "html_ratio                         0.201061     0.230564     0.260770   \n",
       "image_ratio                        0.025900     0.083051     0.236700   \n",
       "lengthyLinkDomain                  0.000000     1.000000     1.000000   \n",
       "linkwordscore                     14.000000    25.000000    43.000000   \n",
       "non_markup_alphanum_characters  1579.000000  3500.000000  6377.000000   \n",
       "numberOfLinks                     82.000000   139.000000   222.000000   \n",
       "numwords_in_url                    3.000000     5.000000     7.000000   \n",
       "parametrizedLinkRatio              0.040984     0.113402     0.241299   \n",
       "spelling_errors_ratio              0.068739     0.089312     0.112376   \n",
       "label                              0.000000     1.000000     1.000000   \n",
       "\n",
       "                                          max  \n",
       "urlid                            10566.000000  \n",
       "avglinksize                        363.000000  \n",
       "commonlinkratio_1                    1.000000  \n",
       "commonlinkratio_2                    1.000000  \n",
       "commonlinkratio_3                    0.980392  \n",
       "commonlinkratio_4                    0.980392  \n",
       "compression_ratio                   21.000000  \n",
       "embed_ratio                          0.250000  \n",
       "framebased                           0.000000  \n",
       "frameTagRatio                        0.444444  \n",
       "hasDomainLink                        1.000000  \n",
       "html_ratio                           0.716883  \n",
       "image_ratio                        113.333333  \n",
       "lengthyLinkDomain                    1.000000  \n",
       "linkwordscore                      100.000000  \n",
       "non_markup_alphanum_characters  207952.000000  \n",
       "numberOfLinks                     4997.000000  \n",
       "numwords_in_url                     22.000000  \n",
       "parametrizedLinkRatio                1.000000  \n",
       "spelling_errors_ratio                1.000000  \n",
       "label                                1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_new_front_page(data_):\n",
    "    dic = {x: 0 for x in data_['website_type'].values}\n",
    "    for x in dic.keys():\n",
    "        if (data_[data_['news_front_page'] == 1]['website_type'].values == x).sum() > (data_[data_['news_front_page'] == 0]['website_type'].values == x).sum():\n",
    "            dic[x] = 1\n",
    "        elif (data_[data_['news_front_page'] == 1]['website_type'].values == x).sum() == (data_[data_['news_front_page'] == 0]['website_type'].values == x).sum():\n",
    "            dic[x] = np.random.randint(2)\n",
    "        else:\n",
    "            dic[x] = 0\n",
    "    \n",
    "    for i in range(data_.shape[0]):\n",
    "        if data_[i:i+1]['news_front_page'].values == -1:\n",
    "            data_[i:i+1]['news_front_page'].replace(-1, dic.get(data_[i:i+1]['website_type'].values[0]), inplace= True)\n",
    "    \n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_link_pre(df_train):\n",
    "    linktrain1 = set(df_train[df_train['label'] == 1]['linkwordscore'].values)\n",
    "    linktrain0 = set(df_train[df_train['label'] == 0]['linkwordscore'].values)\n",
    "    link = list(linktrain1.intersection(linktrain0))\n",
    "    \n",
    "    val_count1 = []\n",
    "    val_count0 = []\n",
    "    for x in link:\n",
    "        ah = df_train[df_train['linkwordscore'] == x]['label'].value_counts()\n",
    "        val_count0.append(ah[0])\n",
    "        val_count1.append(ah[1])\n",
    "        \n",
    "    for x in list(linktrain0 - linktrain1):\n",
    "        link.append(x)\n",
    "        val_count0.append(df_train[df_train['linkwordscore'] == x]['label'].value_counts()[0])\n",
    "        val_count1.append(0)\n",
    "    for x in list(linktrain1 - linktrain0):\n",
    "        link.append(x)\n",
    "        val_count1.append(df_train[df_train['linkwordscore'] == x]['label'].value_counts()[1])\n",
    "        val_count0.append(0)\n",
    "        \n",
    "    rel = []\n",
    "#     ler = []\n",
    "#     for x in range(len(link)):\n",
    "#         if val_count0[x] > val_count1[x]:\n",
    "#             prob_1 = val_count1[x] / (val_count0[x] + val_count1[x]) \n",
    "#             rel.append(sigmoid(-prob_1 - 2*(1-prob_1)))\n",
    "# #             ler.append(0)\n",
    "            \n",
    "#         elif val_count0[x] < val_count1[x]:\n",
    "#             prob_1 = val_count1[x] / (val_count0[x] + val_count1[x]) \n",
    "#             rel.append(sigmoid(prob_1*2 + (1-prob_1)))\n",
    "# #             ler.append(1)\n",
    "#         else:\n",
    "#             prob_1 = val_count1[x] / (val_count0[x] + val_count1[x]) \n",
    "#             rel.append(sigmoid(prob_1 - (1-prob_1)))\n",
    "#             ler.append(np.random.randint(2))\n",
    "    for x in range(len(link)):\n",
    "        prob_1 = val_count1[x] / (val_count0[x] + val_count1[x])\n",
    "        if prob_1 <= 0.4:\n",
    "            rel.append(sigmoid(-prob_1 - 2*(1-prob_1)))\n",
    "            \n",
    "        elif prob_1 >= 0.6:\n",
    "            prob_1 = val_count1[x] / (val_count0[x] + val_count1[x]) \n",
    "            rel.append(sigmoid(prob_1*2 + (1-prob_1)))\n",
    "            \n",
    "        else:\n",
    "            prob_1 = val_count1[x] / (val_count0[x] + val_count1[x]) \n",
    "#             rel.append(sigmoid(prob_1 - (1-prob_1)))\n",
    "            rel.append(sigmoid(2*(prob_1 - (1-prob_1))))\n",
    "    \n",
    "#     linkpd = pd.DataFrame({'linkscore': link, 'label = 1': val_count1, 'label = 0': val_count0, 'result_prob': rel, 'result_quan': ler})\n",
    "    linkpd = pd.DataFrame({'linkscore': link, 'label = 1': val_count1, 'label = 0': val_count0, 'result_prob': rel})\n",
    "\n",
    "    relsprob = []\n",
    "#     relsquan = []\n",
    "    for x in df_train['linkwordscore'].values:\n",
    "        relsprob.append(linkpd[linkpd['linkscore'] == x]['result_prob'].values[0])\n",
    "#         relsquan.append(linkpd[linkpd['linkscore'] == x]['result_quan'].values[0])\n",
    "    \n",
    "#     return relsprob, relsquan\n",
    "    return relsprob, linkpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lld_nol_pre(df_train):\n",
    "    linktrain1 = set(df_train[df_train['lengthyLinkDomain'] == 1]['numberOfLinks'].values)\n",
    "    linktrain0 = set(df_train[df_train['lengthyLinkDomain'] == 0]['numberOfLinks'].values)\n",
    "    link = list(linktrain1.intersection(linktrain0))\n",
    "    \n",
    "    val_count1 = []\n",
    "    val_count0 = []\n",
    "    for x in link:\n",
    "        ah = df_train[df_train['numberOfLinks'] == x]['lengthyLinkDomain'].value_counts()\n",
    "        val_count0.append(ah[0])\n",
    "        val_count1.append(ah[1])\n",
    "        \n",
    "    for x in list(linktrain0 - linktrain1):\n",
    "        link.append(x)\n",
    "        val_count0.append(df_train[df_train['numberOfLinks'] == x]['lengthyLinkDomain'].value_counts()[0])\n",
    "        val_count1.append(0)\n",
    "    for x in list(linktrain1 - linktrain0):\n",
    "        link.append(x)\n",
    "        val_count1.append(df_train[df_train['numberOfLinks'] == x]['lengthyLinkDomain'].value_counts()[1])\n",
    "        val_count0.append(0)\n",
    "        \n",
    "    rel = []\n",
    "    for x in range(len(link)):\n",
    "        prob_1 = val_count1[x] / (val_count0[x] + val_count1[x])\n",
    "        if prob_1 <= 0.4:\n",
    "            rel.append(sigmoid(-prob_1 - 2*(1-prob_1)))\n",
    "            \n",
    "        elif prob_1 >= 0.6:\n",
    "            prob_1 = val_count1[x] / (val_count0[x] + val_count1[x]) \n",
    "            rel.append(sigmoid(prob_1*2 + (1-prob_1)))\n",
    "            \n",
    "        else:\n",
    "            prob_1 = val_count1[x] / (val_count0[x] + val_count1[x]) \n",
    "            rel.append(sigmoid(2*(prob_1 - (1-prob_1))))\n",
    "    \n",
    "    linkpd = pd.DataFrame({'numberOfLinks': link, 'lengthyLinkDomain = 1': val_count1, 'lengthyLinkDomain = 0': val_count0, 'result_prob': rel})\n",
    "\n",
    "    relsprob = []\n",
    "    for x in df_train['numberOfLinks'].values:\n",
    "        relsprob.append(linkpd[linkpd['numberOfLinks'] == x]['result_prob'].values[0])\n",
    "    \n",
    "    return relsprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurizes(data_):\n",
    "    text = data_['url'].str.split('//',n = -1, expand = True)[1]\n",
    "\n",
    "    text2 = []\n",
    "    text3 = []\n",
    "    for x in text:\n",
    "        spli = x.split('/')\n",
    "        text2.append(spli[0])\n",
    "        text3.append(x.split(spli[0] + '/')[1])\n",
    "\n",
    "    subdomain = []\n",
    "    webname = []\n",
    "    domain = []\n",
    "    for x in text2:\n",
    "        spli = x.split('.')\n",
    "        if len(spli) == 2:\n",
    "            subdomain.append('')\n",
    "            webname.append(spli[0])\n",
    "            domain.append(spli[1])\n",
    "        if len(spli) == 3:\n",
    "            subdomain.append(spli[0])\n",
    "            webname.append(spli[1])\n",
    "            domain.append(spli[2])\n",
    "        if len(spli) == 4:\n",
    "            subdomain.append(spli[0])\n",
    "            webname.append(spli[1])\n",
    "            domain.append(spli[2] + '.' + spli[3])    \n",
    "        if len(spli) > 4:\n",
    "            subdomain.append(spli[0])\n",
    "            webname.append(spli[1])\n",
    "            domain.append(spli[2] + '.' + spli[3] + '.' + spli[4])\n",
    "\n",
    "    text4 = []\n",
    "    text5 = []\n",
    "    for x in text3:\n",
    "        spli = x.split('/')\n",
    "        if len(spli) == 1:\n",
    "            text4.append(spli[0])\n",
    "            text5.append('')\n",
    "        else:\n",
    "            text4.append(spli[0])\n",
    "            text5.append(spli[1])   \n",
    "\n",
    "    punctuation = ['.', '?', '!', '=', '-', '_', '%', ':']\n",
    "    for i in range(len(text4)):\n",
    "        for j in punctuation:\n",
    "            text4[i] = text4[i].replace(j, ' ')\n",
    "            text5[i] = text5[i].replace(j, ' ')\n",
    "\n",
    "    website_type = []\n",
    "    website_type2 = [-1 for i in range(len(text5))]\n",
    "    for i, x in enumerate(text4):\n",
    "        spli = x.split(' ')\n",
    "        if len(spli) == 1:\n",
    "            website_type.append(spli[0])\n",
    "        else:\n",
    "            website_type.append(spli[0])\n",
    "            website_type2[i] = spli[1]\n",
    "\n",
    "    for i, x in enumerate(text5):\n",
    "        if x == '':\n",
    "            website_type2[i] = ''\n",
    "        if website_type2[i] == -1:\n",
    "            website_type2[i] = x.split(' ')[0]  \n",
    "    \n",
    "#     rels_prob, rels_quan = new_link_pre(data_)\n",
    "    \n",
    "    # Features from URL\n",
    "    data_['subdomain'] = subdomain\n",
    "    data_['webname'] = webname\n",
    "    data_['domain'] = domain\n",
    "    data_['website_type'] = website_type\n",
    "    data_['website_type'] = data_['website_type'].replace({'2006':'YEAR', '2007':'YEAR', '2008':'YEAR',\n",
    "                                '2009':'YEAR','2010':'YEAR', '2011':'YEAR', '2012':'YEAR','2013':'YEAR',\n",
    "                            '01':'MONTH', '02':'MONTH','03':'MONTH','04':'MONTH','05':'MONTH','06':'MONTH',\n",
    "                            '07':'MONTH','08':'MONTH','09':'MONTH','10':'MONTH','11':'MONTH','12':'MONTH'})\n",
    "    \n",
    "    data_['website_type2'] = website_type2\n",
    "    data_['website_type2'] = data_['website_type2'].replace({'2006':'YEAR', '2007':'YEAR', '2008':'YEAR', \n",
    "                              '2009':'YEAR', '2010':'YEAR','2011':'YEAR', '2012':'YEAR','2013':'YEAR',\n",
    "                            '01':'MONTH', '02':'MONTH','03':'MONTH','04':'MONTH','05':'MONTH','06':'MONTH',\n",
    "                            '07':'MONTH','08':'MONTH','09':'MONTH','10':'MONTH','11':'MONTH','12':'MONTH',})\n",
    "    \n",
    "#     rels_prob = new_link_pre(data_)\n",
    "#     data_['linkscorepredprob'] = rels_prob\n",
    "#     data_['linkscorepredquan'] = rels_quan\n",
    "\n",
    "    data_['wordInHLT'] = data_['non_markup_alphanum_characters'] * data_['linkwordscore'] / 100\n",
    "    data_['wordError'] = data_['non_markup_alphanum_characters'] * data_['spelling_errors_ratio']\n",
    "    \n",
    "    lld = lld_nol_pre(data_)\n",
    "    data_['lld_nol_prob'] = lld\n",
    "    \n",
    "    # Other Features\n",
    "    data_['alchemy_category_score'] = pd.to_numeric(data_['alchemy_category_score'], errors= 'coerce')\n",
    "    data_['alchemy_category_score'].fillna(data_['alchemy_category_score'].mean(), inplace= True)\n",
    "    \n",
    "#     data_['is_news'] = pd.to_numeric(data_['is_news'], errors= 'coerce')\n",
    "#     data_['is_news'].fillna(0, inplace= True)\n",
    "    \n",
    "    data_['news_front_page'] = pd.to_numeric(data_['news_front_page'], errors= 'coerce')\n",
    "    data_['news_front_page'].fillna(-1, inplace= True)\n",
    "    \n",
    "    data_.drop(columns= ['framebased','url', 'urlid', 'boilerplate', 'is_news'], inplace= True)\n",
    "    \n",
    "    # Encoder\n",
    "    le = LabelEncoder()\n",
    "    fea = ['alchemy_category', 'subdomain', 'webname', 'domain', 'website_type', 'website_type2']\n",
    "    for x in fea:\n",
    "        le.fit(data_[x])\n",
    "        data_[x] = le.transform(data_[x])\n",
    "    \n",
    "    data_ = fill_new_front_page(data_)\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fea_importance(new_data, model):\n",
    "    tes = new_data.columns.tolist()\n",
    "    tes.remove(\"label\")\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "    fold_importance_df[\"Feature\"] = tes\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "            .groupby(\"Feature\")\n",
    "            .mean()\n",
    "            .sort_values(by=\"importance\", ascending=False)[:5000].index)\n",
    "\n",
    "    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.barplot(x=\"importance\",\n",
    "                y=\"Feature\",\n",
    "                data=best_features.sort_values(by=\"importance\",\n",
    "                                                ascending=False))\n",
    "    plt.title(model)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    imp = best_features.groupby('Feature')['importance'].median().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.copy()\n",
    "new_data = featurizes(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels_prob, linkpd = new_link_pre(new_data)\n",
    "new_data['linkscorepredprob'] = rels_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = [var for var in new_data.columns if new_data[var].dtype == 'object']\n",
    "\n",
    "# for var in categorical:\n",
    "#   print(new_data[var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensional: 7395 rows, 31 columns\n",
      "Total NA values: 0\n",
      "                           Column Name Data type #Distinct      #NaN\n",
      "                      alchemy_category     int64        14         0\n",
      "                alchemy_category_score   float64      4806         0\n",
      "                           avglinksize   float64      5710         0\n",
      "                     commonlinkratio_1   float64      4476         0\n",
      "                     commonlinkratio_2   float64      4038         0\n",
      "                     commonlinkratio_3   float64      3266         0\n",
      "                     commonlinkratio_4   float64      2695         0\n",
      "                     compression_ratio   float64      6453         0\n",
      "                           embed_ratio   float64       366         0\n",
      "                         frameTagRatio   float64      5911         0\n",
      "                         hasDomainLink     int64         2         0\n",
      "                            html_ratio   float64      7376         0\n",
      "                           image_ratio   float64      5418         0\n",
      "                     lengthyLinkDomain     int64         2         0\n",
      "                         linkwordscore     int64       101         0\n",
      "                       news_front_page   float64         2         0\n",
      "        non_markup_alphanum_characters     int64      5301         0\n",
      "                         numberOfLinks     int64       702         0\n",
      "                       numwords_in_url     int64        23         0\n",
      "                 parametrizedLinkRatio   float64      3922         0\n",
      "                 spelling_errors_ratio   float64      4219         0\n",
      "                                 label     int64         2         0\n",
      "                             subdomain     int64       409         0\n",
      "                               webname     int64      2981         0\n",
      "                                domain     int64        76         0\n",
      "                          website_type     int64      1720         0\n",
      "                         website_type2     int64      1781         0\n",
      "                             wordInHLT   float64      6951         0\n",
      "                             wordError   float64      7193         0\n",
      "                          lld_nol_prob   float64       152         0\n",
      "                     linkscorepredprob   float64        86         0\n"
     ]
    }
   ],
   "source": [
    "info_columns(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alchemy_category</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>3.552130</td>\n",
       "      <td>3.711401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.603334</td>\n",
       "      <td>0.175952</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.538758</td>\n",
       "      <td>0.603334</td>\n",
       "      <td>0.708279</td>\n",
       "      <td>0.999426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avglinksize</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>2.761823</td>\n",
       "      <td>8.619793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.602062</td>\n",
       "      <td>2.088235</td>\n",
       "      <td>2.627451</td>\n",
       "      <td>363.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.468230</td>\n",
       "      <td>0.203133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340370</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.616604</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.214080</td>\n",
       "      <td>0.146743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.202454</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.092062</td>\n",
       "      <td>0.095978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.049262</td>\n",
       "      <td>0.072629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.065065</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compression_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>2.255103</td>\n",
       "      <td>5.704313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442616</td>\n",
       "      <td>0.483680</td>\n",
       "      <td>0.578227</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>-0.103750</td>\n",
       "      <td>0.306545</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frameTagRatio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.056423</td>\n",
       "      <td>0.041446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028502</td>\n",
       "      <td>0.045775</td>\n",
       "      <td>0.073459</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasDomainLink</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>0.144162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>html_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.233778</td>\n",
       "      <td>0.052487</td>\n",
       "      <td>0.045564</td>\n",
       "      <td>0.201061</td>\n",
       "      <td>0.230564</td>\n",
       "      <td>0.260770</td>\n",
       "      <td>0.716883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.275709</td>\n",
       "      <td>1.919320</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.083051</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>113.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.660311</td>\n",
       "      <td>0.473636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linkwordscore</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>30.077079</td>\n",
       "      <td>20.393101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news_front_page</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.065991</td>\n",
       "      <td>0.248282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>5716.598242</td>\n",
       "      <td>8875.432430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1579.000000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>6377.000000</td>\n",
       "      <td>207952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numberOfLinks</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>178.754564</td>\n",
       "      <td>179.466198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>4997.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numwords_in_url</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>4.960649</td>\n",
       "      <td>3.233111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.172864</td>\n",
       "      <td>0.183286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.241299</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.101221</td>\n",
       "      <td>0.079231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068739</td>\n",
       "      <td>0.089312</td>\n",
       "      <td>0.112376</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.513320</td>\n",
       "      <td>0.499856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subdomain</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>275.706558</td>\n",
       "      <td>180.068013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webname</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>1441.983367</td>\n",
       "      <td>884.958611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>657.000000</td>\n",
       "      <td>1330.000000</td>\n",
       "      <td>2202.000000</td>\n",
       "      <td>2980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>21.185260</td>\n",
       "      <td>10.487484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>website_type</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>707.536849</td>\n",
       "      <td>500.191051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1719.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>website_type2</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>604.621501</td>\n",
       "      <td>534.888724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>1780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordInHLT</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>1032.615548</td>\n",
       "      <td>1000.754580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>426.725000</td>\n",
       "      <td>829.800000</td>\n",
       "      <td>1374.450000</td>\n",
       "      <td>23466.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wordError</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>571.461814</td>\n",
       "      <td>1040.772279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.768295</td>\n",
       "      <td>301.481481</td>\n",
       "      <td>612.866980</td>\n",
       "      <td>23584.501749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lld_nol_prob</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.683607</td>\n",
       "      <td>0.276523</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.523792</td>\n",
       "      <td>0.848249</td>\n",
       "      <td>0.864964</td>\n",
       "      <td>0.880797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linkscorepredprob</th>\n",
       "      <td>7395.0</td>\n",
       "      <td>0.532730</td>\n",
       "      <td>0.226914</td>\n",
       "      <td>0.119203</td>\n",
       "      <td>0.445759</td>\n",
       "      <td>0.533284</td>\n",
       "      <td>0.832018</td>\n",
       "      <td>0.880797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count         mean          std       min  \\\n",
       "alchemy_category                7395.0     3.552130     3.711401  0.000000   \n",
       "alchemy_category_score          7395.0     0.603334     0.175952  0.070833   \n",
       "avglinksize                     7395.0     2.761823     8.619793  0.000000   \n",
       "commonlinkratio_1               7395.0     0.468230     0.203133  0.000000   \n",
       "commonlinkratio_2               7395.0     0.214080     0.146743  0.000000   \n",
       "commonlinkratio_3               7395.0     0.092062     0.095978  0.000000   \n",
       "commonlinkratio_4               7395.0     0.049262     0.072629  0.000000   \n",
       "compression_ratio               7395.0     2.255103     5.704313  0.000000   \n",
       "embed_ratio                     7395.0    -0.103750     0.306545 -1.000000   \n",
       "frameTagRatio                   7395.0     0.056423     0.041446  0.000000   \n",
       "hasDomainLink                   7395.0     0.021231     0.144162  0.000000   \n",
       "html_ratio                      7395.0     0.233778     0.052487  0.045564   \n",
       "image_ratio                     7395.0     0.275709     1.919320 -1.000000   \n",
       "lengthyLinkDomain               7395.0     0.660311     0.473636  0.000000   \n",
       "linkwordscore                   7395.0    30.077079    20.393101  0.000000   \n",
       "news_front_page                 7395.0     0.065991     0.248282  0.000000   \n",
       "non_markup_alphanum_characters  7395.0  5716.598242  8875.432430  0.000000   \n",
       "numberOfLinks                   7395.0   178.754564   179.466198  1.000000   \n",
       "numwords_in_url                 7395.0     4.960649     3.233111  0.000000   \n",
       "parametrizedLinkRatio           7395.0     0.172864     0.183286  0.000000   \n",
       "spelling_errors_ratio           7395.0     0.101221     0.079231  0.000000   \n",
       "label                           7395.0     0.513320     0.499856  0.000000   \n",
       "subdomain                       7395.0   275.706558   180.068013  0.000000   \n",
       "webname                         7395.0  1441.983367   884.958611  0.000000   \n",
       "domain                          7395.0    21.185260    10.487484  0.000000   \n",
       "website_type                    7395.0   707.536849   500.191051  0.000000   \n",
       "website_type2                   7395.0   604.621501   534.888724  0.000000   \n",
       "wordInHLT                       7395.0  1032.615548  1000.754580  0.000000   \n",
       "wordError                       7395.0   571.461814  1040.772279  0.000000   \n",
       "lld_nol_prob                    7395.0     0.683607     0.276523  0.119203   \n",
       "linkscorepredprob               7395.0     0.532730     0.226914  0.119203   \n",
       "\n",
       "                                        25%          50%          75%  \\\n",
       "alchemy_category                   0.000000     2.000000     8.000000   \n",
       "alchemy_category_score             0.538758     0.603334     0.708279   \n",
       "avglinksize                        1.602062     2.088235     2.627451   \n",
       "commonlinkratio_1                  0.340370     0.481481     0.616604   \n",
       "commonlinkratio_2                  0.105263     0.202454     0.300000   \n",
       "commonlinkratio_3                  0.022222     0.068627     0.133333   \n",
       "commonlinkratio_4                  0.000000     0.022222     0.065065   \n",
       "compression_ratio                  0.442616     0.483680     0.578227   \n",
       "embed_ratio                        0.000000     0.000000     0.000000   \n",
       "frameTagRatio                      0.028502     0.045775     0.073459   \n",
       "hasDomainLink                      0.000000     0.000000     0.000000   \n",
       "html_ratio                         0.201061     0.230564     0.260770   \n",
       "image_ratio                        0.025900     0.083051     0.236700   \n",
       "lengthyLinkDomain                  0.000000     1.000000     1.000000   \n",
       "linkwordscore                     14.000000    25.000000    43.000000   \n",
       "news_front_page                    0.000000     0.000000     0.000000   \n",
       "non_markup_alphanum_characters  1579.000000  3500.000000  6377.000000   \n",
       "numberOfLinks                     82.000000   139.000000   222.000000   \n",
       "numwords_in_url                    3.000000     5.000000     7.000000   \n",
       "parametrizedLinkRatio              0.040984     0.113402     0.241299   \n",
       "spelling_errors_ratio              0.068739     0.089312     0.112376   \n",
       "label                              0.000000     1.000000     1.000000   \n",
       "subdomain                          0.000000   404.000000   404.000000   \n",
       "webname                          657.000000  1330.000000  2202.000000   \n",
       "domain                            18.000000    18.000000    18.000000   \n",
       "website_type                     337.000000   462.000000  1145.000000   \n",
       "website_type2                      0.000000   527.000000   999.000000   \n",
       "wordInHLT                        426.725000   829.800000  1374.450000   \n",
       "wordError                        118.768295   301.481481   612.866980   \n",
       "lld_nol_prob                       0.523792     0.848249     0.864964   \n",
       "linkscorepredprob                  0.445759     0.533284     0.832018   \n",
       "\n",
       "                                          max  \n",
       "alchemy_category                    13.000000  \n",
       "alchemy_category_score               0.999426  \n",
       "avglinksize                        363.000000  \n",
       "commonlinkratio_1                    1.000000  \n",
       "commonlinkratio_2                    1.000000  \n",
       "commonlinkratio_3                    0.980392  \n",
       "commonlinkratio_4                    0.980392  \n",
       "compression_ratio                   21.000000  \n",
       "embed_ratio                          0.250000  \n",
       "frameTagRatio                        0.444444  \n",
       "hasDomainLink                        1.000000  \n",
       "html_ratio                           0.716883  \n",
       "image_ratio                        113.333333  \n",
       "lengthyLinkDomain                    1.000000  \n",
       "linkwordscore                      100.000000  \n",
       "news_front_page                      1.000000  \n",
       "non_markup_alphanum_characters  207952.000000  \n",
       "numberOfLinks                     4997.000000  \n",
       "numwords_in_url                     22.000000  \n",
       "parametrizedLinkRatio                1.000000  \n",
       "spelling_errors_ratio                1.000000  \n",
       "label                                1.000000  \n",
       "subdomain                          408.000000  \n",
       "webname                           2980.000000  \n",
       "domain                              75.000000  \n",
       "website_type                      1719.000000  \n",
       "website_type2                     1780.000000  \n",
       "wordInHLT                        23466.740000  \n",
       "wordError                        23584.501749  \n",
       "lld_nol_prob                         0.880797  \n",
       "linkscorepredprob                    0.880797  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_word_add = ['becau','abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', 'onc', 'onli', 'ourselv', 'themselv', 'thi', 'veri', 'wa', 'whi', 'yourselv']\n",
    "for i in stop_word_add:\n",
    "    stop_words.append(i)\n",
    "    \n",
    "def preprocessor(text):\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P).,!*-\"', text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "    return text\n",
    "\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = PunktToken().tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(data_):\n",
    "    tfv = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode', analyzer='word',\n",
    "                          token_pattern=r'\\w{1,}', ngram_range=(1, 2), use_idf=1, smooth_idf=1,sublinear_tf=1,\n",
    "                          stop_words= stop_words, tokenizer= tokenizer_porter, preprocessor= preprocessor)\n",
    "    tfv.fit(data_['body'])\n",
    "    data_['body'] = tfv.transform(data_['body'])\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def documentFrequencyVector(trainData):\n",
    "    tfv = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode', analyzer='word',\n",
    "                          token_pattern=r'\\w{1,}', ngram_range=(1, 2), use_idf=1, smooth_idf=1,sublinear_tf=1,\n",
    "                          stop_words= stop_words, tokenizer= tokenizer_porter, preprocessor= preprocessor)\n",
    "    tfv.fit(trainData)\n",
    "    X = tfv.transform(trainData)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA parameters\n",
    "numTopics = 1000\n",
    "numIterations = 50\n",
    "\n",
    "def transformInLDATopics(trainData):\n",
    "    trainData = documentFrequencyVector(trainData)\n",
    "    model = lda.LDA(n_topics=numTopics, n_iter=numIterations, random_state=1)\n",
    "    model.fit(trainData)\n",
    "    doc_topic = model.doc_topic_\n",
    "    return doc_topic\n",
    "\n",
    "def getLdaTopicsVector(trainData):\n",
    "    doc_topic = transformInLDATopics(trainData)\n",
    "    topicVector = []\n",
    "    for i in range(X.shape[0]):\n",
    "        topicVector.append(doc_topic[i].argmax())\n",
    "    return topicVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = data[['boilerplate', 'label']]\n",
    "\n",
    "boilerplate = main_data['boilerplate']\n",
    "\n",
    "dicts = {\n",
    "    'title' : [],\n",
    "    'body' : [],\n",
    "    'url' : []\n",
    "}\n",
    "for i in range(len(boilerplate)):\n",
    "    temp = json.loads(boilerplate[i])\n",
    "    for j in dicts.keys():\n",
    "        dicts[j].append(temp.get(j, None))\n",
    "        \n",
    "text_data = pd.DataFrame()\n",
    "text_data['title'] = dicts['title']\n",
    "text_data['body'] = dicts['body']\n",
    "text_data['url'] = dicts['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNanAndNone(data_):\n",
    "    fea = ['title', 'body', 'url']\n",
    "    for name in fea:\n",
    "        data_[name].fillna(\" \", inplace= True)\n",
    "    return data_\n",
    "\n",
    "text_data = fillNanAndNone(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode', analyzer='word', sublinear_tf=True,\n",
    "                token_pattern=r'\\w{1,}', ngram_range=(1, 2), use_idf= True, smooth_idf= True, binary=False,\n",
    "                stop_words= stop_words, tokenizer= tokenizer_porter, preprocessor= preprocessor)\n",
    "\n",
    "bodyVect = tfv.fit_transform(text_data['body'])\n",
    "titleVect = tfv.fit_transform(text_data['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DUM_?</th>\n",
       "      <th>DUM_arts_entertainment</th>\n",
       "      <th>DUM_business</th>\n",
       "      <th>DUM_computer_internet</th>\n",
       "      <th>DUM_culture_politics</th>\n",
       "      <th>DUM_gaming</th>\n",
       "      <th>DUM_health</th>\n",
       "      <th>DUM_law_crime</th>\n",
       "      <th>DUM_recreation</th>\n",
       "      <th>DUM_religion</th>\n",
       "      <th>DUM_science_technology</th>\n",
       "      <th>DUM_sports</th>\n",
       "      <th>DUM_unknown</th>\n",
       "      <th>DUM_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7395 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DUM_?  DUM_arts_entertainment  DUM_business  DUM_computer_internet  \\\n",
       "0         0                       0             1                      0   \n",
       "1         0                       0             0                      0   \n",
       "2         0                       0             0                      0   \n",
       "3         0                       0             0                      0   \n",
       "4         0                       0             0                      0   \n",
       "...     ...                     ...           ...                    ...   \n",
       "7390      0                       0             0                      1   \n",
       "7391      0                       0             0                      0   \n",
       "7392      0                       0             0                      0   \n",
       "7393      0                       1             0                      0   \n",
       "7394      1                       0             0                      0   \n",
       "\n",
       "      DUM_culture_politics  DUM_gaming  DUM_health  DUM_law_crime  \\\n",
       "0                        0           0           0              0   \n",
       "1                        0           0           0              0   \n",
       "2                        0           0           1              0   \n",
       "3                        0           0           1              0   \n",
       "4                        0           0           0              0   \n",
       "...                    ...         ...         ...            ...   \n",
       "7390                     0           0           0              0   \n",
       "7391                     1           0           0              0   \n",
       "7392                     0           0           0              0   \n",
       "7393                     0           0           0              0   \n",
       "7394                     0           0           0              0   \n",
       "\n",
       "      DUM_recreation  DUM_religion  DUM_science_technology  DUM_sports  \\\n",
       "0                  0             0                       0           0   \n",
       "1                  1             0                       0           0   \n",
       "2                  0             0                       0           0   \n",
       "3                  0             0                       0           0   \n",
       "4                  0             0                       0           1   \n",
       "...              ...           ...                     ...         ...   \n",
       "7390               0             0                       0           0   \n",
       "7391               0             0                       0           0   \n",
       "7392               1             0                       0           0   \n",
       "7393               0             0                       0           0   \n",
       "7394               0             0                       0           0   \n",
       "\n",
       "      DUM_unknown  DUM_weather  \n",
       "0               0            0  \n",
       "1               0            0  \n",
       "2               0            0  \n",
       "3               0            0  \n",
       "4               0            0  \n",
       "...           ...          ...  \n",
       "7390            0            0  \n",
       "7391            0            0  \n",
       "7392            0            0  \n",
       "7393            0            0  \n",
       "7394            0            0  \n",
       "\n",
       "[7395 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alchemyCategories_df = pd.get_dummies(data.alchemy_category, prefix = 'DUM')\n",
    "alchemyCategories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleDecomposed = TruncatedSVD(random_state = 123, n_components = 10).fit_transform(titleVect)\n",
    "bodyDecomposed = TruncatedSVD(random_state = 123, n_components = 50).fit_transform(bodyVect)\n",
    "\n",
    "textDecomposed = np.hstack([titleDecomposed,bodyDecomposed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>embed_ratio</th>\n",
       "      <th>frameTagRatio</th>\n",
       "      <th>...</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>webname</th>\n",
       "      <th>domain</th>\n",
       "      <th>website_type</th>\n",
       "      <th>website_type2</th>\n",
       "      <th>wordInHLT</th>\n",
       "      <th>wordError</th>\n",
       "      <th>lld_nol_prob</th>\n",
       "      <th>linkscorepredprob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.443783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>404</td>\n",
       "      <td>321</td>\n",
       "      <td>18</td>\n",
       "      <td>1145</td>\n",
       "      <td>612</td>\n",
       "      <td>1301.76</td>\n",
       "      <td>429.198815</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.553639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.574147</td>\n",
       "      <td>3.677966</td>\n",
       "      <td>0.508021</td>\n",
       "      <td>0.288770</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>0.468649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125448</td>\n",
       "      <td>404</td>\n",
       "      <td>2015</td>\n",
       "      <td>18</td>\n",
       "      <td>1529</td>\n",
       "      <td>666</td>\n",
       "      <td>1989.20</td>\n",
       "      <td>623.853048</td>\n",
       "      <td>0.862158</td>\n",
       "      <td>0.448460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>2.382883</td>\n",
       "      <td>0.562016</td>\n",
       "      <td>0.321705</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.042636</td>\n",
       "      <td>0.525448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057613</td>\n",
       "      <td>404</td>\n",
       "      <td>1614</td>\n",
       "      <td>18</td>\n",
       "      <td>888</td>\n",
       "      <td>1028</td>\n",
       "      <td>1232.00</td>\n",
       "      <td>129.053499</td>\n",
       "      <td>0.860348</td>\n",
       "      <td>0.163614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.801248</td>\n",
       "      <td>1.543103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100858</td>\n",
       "      <td>404</td>\n",
       "      <td>705</td>\n",
       "      <td>18</td>\n",
       "      <td>337</td>\n",
       "      <td>527</td>\n",
       "      <td>656.88</td>\n",
       "      <td>276.049356</td>\n",
       "      <td>0.839185</td>\n",
       "      <td>0.553639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.719157</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.446143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>18</td>\n",
       "      <td>395</td>\n",
       "      <td>60</td>\n",
       "      <td>1684.48</td>\n",
       "      <td>993.467886</td>\n",
       "      <td>0.867036</td>\n",
       "      <td>0.581679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>3</td>\n",
       "      <td>0.651067</td>\n",
       "      <td>3.010526</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.474273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>2441</td>\n",
       "      <td>18</td>\n",
       "      <td>337</td>\n",
       "      <td>527</td>\n",
       "      <td>843.22</td>\n",
       "      <td>158.499999</td>\n",
       "      <td>0.582570</td>\n",
       "      <td>0.492538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>4</td>\n",
       "      <td>0.141920</td>\n",
       "      <td>2.208054</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.558184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>404</td>\n",
       "      <td>2732</td>\n",
       "      <td>18</td>\n",
       "      <td>524</td>\n",
       "      <td>1743</td>\n",
       "      <td>1928.48</td>\n",
       "      <td>620.815919</td>\n",
       "      <td>0.880797</td>\n",
       "      <td>0.445759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>8</td>\n",
       "      <td>0.196273</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.692529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>99</td>\n",
       "      <td>1614</td>\n",
       "      <td>18</td>\n",
       "      <td>1433</td>\n",
       "      <td>1624</td>\n",
       "      <td>364.64</td>\n",
       "      <td>99.764706</td>\n",
       "      <td>0.835019</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>1</td>\n",
       "      <td>0.617876</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1749</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142.82</td>\n",
       "      <td>128.666667</td>\n",
       "      <td>0.149912</td>\n",
       "      <td>0.409607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>0</td>\n",
       "      <td>0.603334</td>\n",
       "      <td>1.158209</td>\n",
       "      <td>0.505917</td>\n",
       "      <td>0.428994</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134146</td>\n",
       "      <td>323</td>\n",
       "      <td>478</td>\n",
       "      <td>18</td>\n",
       "      <td>337</td>\n",
       "      <td>1626</td>\n",
       "      <td>401.70</td>\n",
       "      <td>69.085366</td>\n",
       "      <td>0.124294</td>\n",
       "      <td>0.444672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7395 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alchemy_category  alchemy_category_score  avglinksize  \\\n",
       "0                    2                0.789131     2.055556   \n",
       "1                    8                0.574147     3.677966   \n",
       "2                    6                0.996526     2.382883   \n",
       "3                    6                0.801248     1.543103   \n",
       "4                   11                0.719157     2.676471   \n",
       "...                ...                     ...          ...   \n",
       "7390                 3                0.651067     3.010526   \n",
       "7391                 4                0.141920     2.208054   \n",
       "7392                 8                0.196273     2.000000   \n",
       "7393                 1                0.617876     1.026316   \n",
       "7394                 0                0.603334     1.158209   \n",
       "\n",
       "      commonlinkratio_1  commonlinkratio_2  commonlinkratio_3  \\\n",
       "0              0.676471           0.205882           0.047059   \n",
       "1              0.508021           0.288770           0.213904   \n",
       "2              0.562016           0.321705           0.120155   \n",
       "3              0.400000           0.100000           0.016667   \n",
       "4              0.500000           0.222222           0.123457   \n",
       "...                 ...                ...                ...   \n",
       "7390           0.474747           0.222222           0.191919   \n",
       "7391           0.483333           0.246667           0.036667   \n",
       "7392           0.315789           0.171053           0.105263   \n",
       "7393           0.210526           0.052632           0.000000   \n",
       "7394           0.505917           0.428994           0.023669   \n",
       "\n",
       "      commonlinkratio_4  compression_ratio  embed_ratio  frameTagRatio  ...  \\\n",
       "0              0.023529           0.443783          0.0       0.090774  ...   \n",
       "1              0.144385           0.468649          0.0       0.098707  ...   \n",
       "2              0.042636           0.525448          0.0       0.072448  ...   \n",
       "3              0.000000           0.480725          0.0       0.095861  ...   \n",
       "4              0.043210           0.446143          0.0       0.024908  ...   \n",
       "...                 ...                ...          ...            ...  ...   \n",
       "7390           0.191919           0.474273          0.0       0.177043  ...   \n",
       "7391           0.026667           0.558184          0.0       0.057377  ...   \n",
       "7392           0.052632           0.692529          0.0       0.124122  ...   \n",
       "7393           0.000000          21.000000         -1.0       0.097778  ...   \n",
       "7394           0.000000           0.434146          0.0       0.028451  ...   \n",
       "\n",
       "      spelling_errors_ratio  subdomain  webname  domain  website_type  \\\n",
       "0                  0.079130        404      321      18          1145   \n",
       "1                  0.125448        404     2015      18          1529   \n",
       "2                  0.057613        404     1614      18           888   \n",
       "3                  0.100858        404      705      18           337   \n",
       "4                  0.082569          0      307      18           395   \n",
       "...                     ...        ...      ...     ...           ...   \n",
       "7390               0.071429          0     2441      18           337   \n",
       "7391               0.109453        404     2732      18           524   \n",
       "7392               0.117647         99     1614      18          1433   \n",
       "7393               0.333333          0     1749      18             0   \n",
       "7394               0.134146        323      478      18           337   \n",
       "\n",
       "      website_type2  wordInHLT   wordError  lld_nol_prob  linkscorepredprob  \n",
       "0               612    1301.76  429.198815      0.855422           0.553639  \n",
       "1               666    1989.20  623.853048      0.862158           0.448460  \n",
       "2              1028    1232.00  129.053499      0.860348           0.163614  \n",
       "3               527     656.88  276.049356      0.839185           0.553639  \n",
       "4                60    1684.48  993.467886      0.867036           0.581679  \n",
       "...             ...        ...         ...           ...                ...  \n",
       "7390            527     843.22  158.499999      0.582570           0.492538  \n",
       "7391           1743    1928.48  620.815919      0.880797           0.445759  \n",
       "7392           1624     364.64   99.764706      0.835019           0.500000  \n",
       "7393              0     142.82  128.666667      0.149912           0.409607  \n",
       "7394           1626     401.70   69.085366      0.124294           0.444672  \n",
       "\n",
       "[7395 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain = new_data[[x for x in new_data.columns if x != 'label']]\n",
    "dataTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (5916, 104) (5916,)\n",
      "Test set: (1479, 104) (1479,)\n"
     ]
    }
   ],
   "source": [
    "yt = new_data.label\n",
    "Xt = np.concatenate((dataTrain, alchemy_dum_alt[data_test.shape[0]:].values), 1)\n",
    "X_alt = np.hstack([Xt, textDecomposed])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_alt, yt, test_size=0.2, random_state=102)\n",
    "\n",
    "print('Training set:', X_train.shape, y_train.shape)\n",
    "print('Test set:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7395, 14)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alchemy_dum_alt[:data.shape[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classifiers = [\n",
    "                    ('Random Forest', RandomForestClassifier(n_estimators=1000, n_jobs= 4, min_samples_leaf= 2, bootstrap= True, min_samples_split= 5, max_features= .1, max_samples= 30)),\n",
    "                    ('AdaBoost Classifier', AdaBoostClassifier()),\n",
    "                    ('Gradient Boosting Classifier', GradientBoostingClassifier(n_estimators= 300, learning_rate= 0.08, max_features= 4, min_samples_leaf= 2, min_samples_split= 5, max_depth= 7)),\n",
    "                    ('Extra Trees Classifier', ExtraTreesClassifier()),\n",
    "                    ('LightGBM', LGBMClassifier(n_estimators= 300, learning_rate= 0.08, num_leaves= 50,boosting_type= 'gbdt', objective= 'binary', sub_feature= 0.5, max_depth= 7)),\n",
    "                    ('XGBM', XGBClassifier())]\n",
    "\n",
    "# ('KNN', KNeighborsClassifier()),\n",
    "# ('Naive Bayes', GaussianNB()),\n",
    "# ('Decision Tree', DecisionTreeClassifier()),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[00:38:02] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[00:41:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:41:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:42:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:42:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:43:07] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[00:44:31] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[00:48:09] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:48:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:49:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:49:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:50:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[00:52:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[00:55:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:56:08] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:56:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:56:59] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "pred_prob = []\n",
    "for x in range(3):\n",
    "    clf = StackingClassifier(estimators= base_classifiers, final_estimator= LogisticRegression())\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred_prob.append(clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_prob(lis):\n",
    "    return np.mean(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc_auc_accu 86.07912984961087\n"
     ]
    }
   ],
   "source": [
    "lis = [[] for i in range(y_test.shape[0])]\n",
    "for i in range(y_test.shape[0]):\n",
    "    for j in range(len(pred_prob)):\n",
    "            lis[i].append(pred_prob[j][i])\n",
    "            \n",
    "rel = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    rel.append(voting_prob(lis[i]))\n",
    "    \n",
    "print(\"Roc_auc_accu\", roc_auc_score(y_test, rel) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossVal(clf, X_data, Y_data, NFOLDS = 10): \n",
    "    import sklearn.ensemble as ens\n",
    "    from sklearn import metrics\n",
    "    from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "    skf = StratifiedKFold(Y_data, n_folds = NFOLDS)\n",
    "    auc = []\n",
    "    for train_index, test_index in skf:\n",
    "        x_train, x_test = X_data[train_index], X_data[test_index]\n",
    "        y_train, y_test = Y_data[train_index], Y_data[test_index]\n",
    "        \n",
    "        clf.fit(x_train, y_train)\n",
    "        \n",
    "        try: \n",
    "            probs = clf.predict_proba(x_test)\n",
    "            y_hat = probs[:,1]\n",
    "        except:\n",
    "            y_hat = clf.predict(x_test)\n",
    "        auc.append(metrics.roc_auc_score(y_test, y_hat))\n",
    "    print(auc)\n",
    "    print(np.mean(auc))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters3 = {'learning_rate': [0.05, 0.1, 0.25, 0.5, 0.75],\n",
    "              'n_estimators' : [100, 300, 500, 700, 1000, 2000, 4000],\n",
    "              'max_depth' : [2,3,4,5,10,15,20,50,100],\n",
    "              'min_samples_split' : [2,4,6,8,10],\n",
    "              'min_samples_leaf' : [1,2,5],\n",
    "              'subsample' : [0.5, 0.75, 1]}\n",
    "clfGBMGrid = GridSearchCV(GradientBoostingClassifier(random_state = 123), parameters3).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test.tsv', sep ='\\t')\n",
    "new_data_test = data_test.copy()\n",
    "new_data_test = featurizes(new_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "for x in new_data_test['linkwordscore'].values:\n",
    "    prob.append(linkpd[linkpd['linkscore'] == x]['result_prob'].values[0])\n",
    "    \n",
    "new_data_test['linkscorepredprob'] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_test = data_test[['boilerplate']]\n",
    "\n",
    "boilerplate_test = main_data_test['boilerplate']\n",
    "\n",
    "dicts_test = {\n",
    "    'title' : [],\n",
    "    'body' : [],\n",
    "    'url' : []\n",
    "}\n",
    "for i in range(len(boilerplate_test)):\n",
    "    temp = json.loads(boilerplate_test[i])\n",
    "    for j in dicts_test.keys():\n",
    "        dicts_test[j].append(temp.get(j, None))\n",
    "        \n",
    "text_data_test = pd.DataFrame()\n",
    "text_data_test['title'] = dicts_test['title']\n",
    "text_data_test['body'] = dicts_test['body']\n",
    "text_data_test['url'] = dicts_test['url']\n",
    "\n",
    "text_data_test = fillNanAndNone(text_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyVect_test = tfv.fit_transform(text_data_test['body'])\n",
    "titleVect_test = tfv.fit_transform(text_data_test['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DUM_?</th>\n",
       "      <th>DUM_arts_entertainment</th>\n",
       "      <th>DUM_business</th>\n",
       "      <th>DUM_computer_internet</th>\n",
       "      <th>DUM_culture_politics</th>\n",
       "      <th>DUM_gaming</th>\n",
       "      <th>DUM_health</th>\n",
       "      <th>DUM_law_crime</th>\n",
       "      <th>DUM_recreation</th>\n",
       "      <th>DUM_religion</th>\n",
       "      <th>DUM_science_technology</th>\n",
       "      <th>DUM_sports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3171 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DUM_?  DUM_arts_entertainment  DUM_business  DUM_computer_internet  \\\n",
       "0         0                       0             0                      0   \n",
       "1         0                       0             0                      0   \n",
       "2         1                       0             0                      0   \n",
       "3         0                       0             0                      0   \n",
       "4         0                       0             0                      0   \n",
       "...     ...                     ...           ...                    ...   \n",
       "3166      1                       0             0                      0   \n",
       "3167      1                       0             0                      0   \n",
       "3168      1                       0             0                      0   \n",
       "3169      0                       0             0                      0   \n",
       "3170      0                       1             0                      0   \n",
       "\n",
       "      DUM_culture_politics  DUM_gaming  DUM_health  DUM_law_crime  \\\n",
       "0                        0           0           0              0   \n",
       "1                        1           0           0              0   \n",
       "2                        0           0           0              0   \n",
       "3                        1           0           0              0   \n",
       "4                        0           0           0              0   \n",
       "...                    ...         ...         ...            ...   \n",
       "3166                     0           0           0              0   \n",
       "3167                     0           0           0              0   \n",
       "3168                     0           0           0              0   \n",
       "3169                     0           0           0              0   \n",
       "3170                     0           0           0              0   \n",
       "\n",
       "      DUM_recreation  DUM_religion  DUM_science_technology  DUM_sports  \n",
       "0                  1             0                       0           0  \n",
       "1                  0             0                       0           0  \n",
       "2                  0             0                       0           0  \n",
       "3                  0             0                       0           0  \n",
       "4                  0             0                       1           0  \n",
       "...              ...           ...                     ...         ...  \n",
       "3166               0             0                       0           0  \n",
       "3167               0             0                       0           0  \n",
       "3168               0             0                       0           0  \n",
       "3169               0             0                       0           1  \n",
       "3170               0             0                       0           0  \n",
       "\n",
       "[3171 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alchemyCategories_df_test = pd.get_dummies(data_test.alchemy_category, prefix = 'DUM')\n",
    "alchemyCategories_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DUM_?</th>\n",
       "      <th>DUM_arts_entertainment</th>\n",
       "      <th>DUM_business</th>\n",
       "      <th>DUM_computer_internet</th>\n",
       "      <th>DUM_culture_politics</th>\n",
       "      <th>DUM_gaming</th>\n",
       "      <th>DUM_health</th>\n",
       "      <th>DUM_law_crime</th>\n",
       "      <th>DUM_recreation</th>\n",
       "      <th>DUM_religion</th>\n",
       "      <th>DUM_science_technology</th>\n",
       "      <th>DUM_sports</th>\n",
       "      <th>DUM_unknown</th>\n",
       "      <th>DUM_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3171 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DUM_?  DUM_arts_entertainment  DUM_business  DUM_computer_internet  \\\n",
       "4224      0                       1             0                      0   \n",
       "4225      0                       0             0                      0   \n",
       "4226      0                       0             0                      0   \n",
       "4227      0                       0             1                      0   \n",
       "4228      1                       0             0                      0   \n",
       "...     ...                     ...           ...                    ...   \n",
       "7390      0                       0             0                      1   \n",
       "7391      0                       0             0                      0   \n",
       "7392      0                       0             0                      0   \n",
       "7393      0                       1             0                      0   \n",
       "7394      1                       0             0                      0   \n",
       "\n",
       "      DUM_culture_politics  DUM_gaming  DUM_health  DUM_law_crime  \\\n",
       "4224                     0           0           0              0   \n",
       "4225                     0           0           0              0   \n",
       "4226                     0           0           0              0   \n",
       "4227                     0           0           0              0   \n",
       "4228                     0           0           0              0   \n",
       "...                    ...         ...         ...            ...   \n",
       "7390                     0           0           0              0   \n",
       "7391                     1           0           0              0   \n",
       "7392                     0           0           0              0   \n",
       "7393                     0           0           0              0   \n",
       "7394                     0           0           0              0   \n",
       "\n",
       "      DUM_recreation  DUM_religion  DUM_science_technology  DUM_sports  \\\n",
       "4224               0             0                       0           0   \n",
       "4225               1             0                       0           0   \n",
       "4226               1             0                       0           0   \n",
       "4227               0             0                       0           0   \n",
       "4228               0             0                       0           0   \n",
       "...              ...           ...                     ...         ...   \n",
       "7390               0             0                       0           0   \n",
       "7391               0             0                       0           0   \n",
       "7392               1             0                       0           0   \n",
       "7393               0             0                       0           0   \n",
       "7394               0             0                       0           0   \n",
       "\n",
       "      DUM_unknown  DUM_weather  \n",
       "4224            0            0  \n",
       "4225            0            0  \n",
       "4226            0            0  \n",
       "4227            0            0  \n",
       "4228            0            0  \n",
       "...           ...          ...  \n",
       "7390            0            0  \n",
       "7391            0            0  \n",
       "7392            0            0  \n",
       "7393            0            0  \n",
       "7394            0            0  \n",
       "\n",
       "[3171 rows x 14 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alchemy_dum_alt[data.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleDecomposed_test = TruncatedSVD(random_state = 123, n_components = 10).fit_transform(titleVect_test)\n",
    "bodyDecomposed_test = TruncatedSVD(random_state = 123, n_components = 50).fit_transform(bodyVect_test)\n",
    "\n",
    "textDecomposed_test = np.hstack([titleDecomposed_test,bodyDecomposed_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_test = np.concatenate((new_data_test, alchemy_dum_alt[:data_test.shape[0]].values), 1)\n",
    "X_alt_test = np.hstack([Xt_test, textDecomposed_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "alchemy_alt = data_test['alchemy_category'].append(data['alchemy_category'])\n",
    "alchemy_dum_alt = pd.get_dummies(alchemy_alt, prefix = 'DUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[10:04:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[10:05:53] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:05:58] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:06:03] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:06:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:06:16] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[10:06:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[10:07:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:07:56] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:08:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:08:06] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:08:11] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[10:08:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set with sub_feature=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[10:09:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:09:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:09:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:09:55] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:10:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "pred_prob = []\n",
    "for x in range(3):\n",
    "    clf = StackingClassifier(estimators= base_classifiers, final_estimator= LogisticRegression())\n",
    "    clf.fit(X_alt, yt)\n",
    "    pred_prob.append(clf.predict_proba(X_alt_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [[] for i in range(data_test.shape[0])]\n",
    "for i in range(data_test.shape[0]):\n",
    "    for j in range(len(pred_prob)):\n",
    "            lis[i].append(pred_prob[j][i])\n",
    "            \n",
    "rel = []\n",
    "for i in range(data_test.shape[0]):\n",
    "    rel.append(voting_prob(lis[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7565313952715192,\n",
       " 0.718988217317968,\n",
       " 0.3458959415760187,\n",
       " 0.786802517202252,\n",
       " 0.6809289039709885,\n",
       " 0.7962149366847516,\n",
       " 0.7343741286385095,\n",
       " 0.8067536786418253,\n",
       " 0.718422891074363,\n",
       " 0.514851667832774,\n",
       " 0.6314197667051171,\n",
       " 0.46167208517634756,\n",
       " 0.5919986424676389,\n",
       " 0.514329512099625,\n",
       " 0.7678246494768045,\n",
       " 0.8405749508618611,\n",
       " 0.6261431095849411,\n",
       " 0.7077582016255741,\n",
       " 0.8469117871563765,\n",
       " 0.6744440234454987,\n",
       " 0.5171634993629045,\n",
       " 0.7189617174444235,\n",
       " 0.689566744948185,\n",
       " 0.7325683451118866,\n",
       " 0.7098949997434737,\n",
       " 0.35659358301614175,\n",
       " 0.785142387239246,\n",
       " 0.6240367378641202,\n",
       " 0.6970943429315309,\n",
       " 0.7105404543956011,\n",
       " 0.6579577678251297,\n",
       " 0.7921519851093817,\n",
       " 0.7073734744785046,\n",
       " 0.7636973563094624,\n",
       " 0.8327600263866479,\n",
       " 0.7608682201521165,\n",
       " 0.7991737191377389,\n",
       " 0.8896509908212908,\n",
       " 0.7491848846761772,\n",
       " 0.6727441588079307,\n",
       " 0.6037643253216389,\n",
       " 0.7543270909948959,\n",
       " 0.19403140437610444,\n",
       " 0.6849357815241778,\n",
       " 0.7943331285559944,\n",
       " 0.8252861326169217,\n",
       " 0.876433989255815,\n",
       " 0.7917478855550838,\n",
       " 0.5703959723992468,\n",
       " 0.7951436123819274,\n",
       " 0.752079542487231,\n",
       " 0.6407975832248013,\n",
       " 0.7283033917785041,\n",
       " 0.6712753419910392,\n",
       " 0.6741910981139788,\n",
       " 0.8051821371066371,\n",
       " 0.7622762343765448,\n",
       " 0.6313833603704991,\n",
       " 0.8339375332258537,\n",
       " 0.6655782278450396,\n",
       " 0.6601693991495958,\n",
       " 0.4986191054693201,\n",
       " 0.698096427738809,\n",
       " 0.6110779274298902,\n",
       " 0.7051933675954967,\n",
       " 0.7321212773246462,\n",
       " 0.7277182959488258,\n",
       " 0.6936324814620024,\n",
       " 0.6674536821553817,\n",
       " 0.6889726910946297,\n",
       " 0.3259283321786256,\n",
       " 0.8291558652132442,\n",
       " 0.7794777970675332,\n",
       " 0.1891976084469842,\n",
       " 0.875385857073894,\n",
       " 0.7346767050592419,\n",
       " 0.6802149632825526,\n",
       " 0.6249540493392859,\n",
       " 0.6967661103146652,\n",
       " 0.44853877022992084,\n",
       " 0.771119325634284,\n",
       " 0.669137162033536,\n",
       " 0.6199517324010829,\n",
       " 0.8488416048331562,\n",
       " 0.7894012578622394,\n",
       " 0.6830122892494009,\n",
       " 0.807633631173377,\n",
       " 0.7346779830422093,\n",
       " 0.2565208549359756,\n",
       " 0.6178388411410991,\n",
       " 0.7321361075788074,\n",
       " 0.8030221128617351,\n",
       " 0.7499307483003418,\n",
       " 0.7507731881605416,\n",
       " 0.6787640896882134,\n",
       " 0.7946676576560069,\n",
       " 0.23342665550405703,\n",
       " 0.7766329607951538,\n",
       " 0.8350588815969694,\n",
       " 0.5267995736139538,\n",
       " 0.6987286108066342,\n",
       " 0.7375710621458901,\n",
       " 0.8470749655982305,\n",
       " 0.8236234340039984,\n",
       " 0.7711968626837074,\n",
       " 0.7688676170388241,\n",
       " 0.5076981332131979,\n",
       " 0.7851281304343868,\n",
       " 0.7379356269876487,\n",
       " 0.6477630248413546,\n",
       " 0.4727835128029699,\n",
       " 0.6770877065568759,\n",
       " 0.44211704736024693,\n",
       " 0.8096094221188782,\n",
       " 0.2461422879988194,\n",
       " 0.8432607997598239,\n",
       " 0.7544803182078305,\n",
       " 0.5045660675215698,\n",
       " 0.5871418352645534,\n",
       " 0.7394139301595142,\n",
       " 0.7364551805751263,\n",
       " 0.7927404910282078,\n",
       " 0.8288317314925019,\n",
       " 0.6495923512653651,\n",
       " 0.8204669573865336,\n",
       " 0.7445751064651537,\n",
       " 0.8737066477605829,\n",
       " 0.6420202197990185,\n",
       " 0.7824435462283729,\n",
       " 0.7808379522785535,\n",
       " 0.7536191142803523,\n",
       " 0.7199855856307712,\n",
       " 0.8495293218917097,\n",
       " 0.7678341940439797,\n",
       " 0.8324625066414949,\n",
       " 0.48996943438941204,\n",
       " 0.7832001311682212,\n",
       " 0.84430650338725,\n",
       " 0.8482152721192086,\n",
       " 0.7495041339966887,\n",
       " 0.8275210395083265,\n",
       " 0.7053587735889638,\n",
       " 0.8347714198715961,\n",
       " 0.8198053460666511,\n",
       " 0.5400619493933414,\n",
       " 0.6389488675473752,\n",
       " 0.8185909143587905,\n",
       " 0.6258608127673421,\n",
       " 0.5086653292595674,\n",
       " 0.6834088660255581,\n",
       " 0.6968356115142996,\n",
       " 0.7764360388391732,\n",
       " 0.7086847563186621,\n",
       " 0.6445092792233783,\n",
       " 0.5046699927857107,\n",
       " 0.8520201060327327,\n",
       " 0.6839531534820011,\n",
       " 0.5263613368671771,\n",
       " 0.8311656493983026,\n",
       " 0.7090244075457136,\n",
       " 0.6497094704673819,\n",
       " 0.8391543805972649,\n",
       " 0.5821450414527551,\n",
       " 0.6984970764527082,\n",
       " 0.7184264813536926,\n",
       " 0.8414171370982192,\n",
       " 0.7480523059560324,\n",
       " 0.7632483431603028,\n",
       " 0.6011038214728908,\n",
       " 0.6273018611261514,\n",
       " 0.619189742777396,\n",
       " 0.8840823169795904,\n",
       " 0.5286544994207245,\n",
       " 0.7834299643715185,\n",
       " 0.7077089734052109,\n",
       " 0.6166777746825661,\n",
       " 0.6935064789103992,\n",
       " 0.8545650584461538,\n",
       " 0.820227387874687,\n",
       " 0.7626284994520427,\n",
       " 0.5113424464915585,\n",
       " 0.3146580527083964,\n",
       " 0.21954591618367333,\n",
       " 0.23080163758357952,\n",
       " 0.17595737129746572,\n",
       " 0.804897967998962,\n",
       " 0.7803377335096716,\n",
       " 0.7790517200672245,\n",
       " 0.610487945697506,\n",
       " 0.7501526776293557,\n",
       " 0.8277250574565542,\n",
       " 0.7456876587077007,\n",
       " 0.6685436547680778,\n",
       " 0.8411319218456784,\n",
       " 0.552474910311283,\n",
       " 0.7896522590536633,\n",
       " 0.815478132081429,\n",
       " 0.5673017612302229,\n",
       " 0.7639001145917881,\n",
       " 0.8394850832266055,\n",
       " 0.8420433206650092,\n",
       " 0.8027460113887851,\n",
       " 0.8362580355272762,\n",
       " 0.7382750592484434,\n",
       " 0.6808805933058579,\n",
       " 0.5958030581261394,\n",
       " 0.7929628327408876,\n",
       " 0.46115504176710403,\n",
       " 0.373435260884527,\n",
       " 0.6276262701212948,\n",
       " 0.6575285204937212,\n",
       " 0.7498615523989005,\n",
       " 0.7083332159076935,\n",
       " 0.5032222782395777,\n",
       " 0.8210303889097178,\n",
       " 0.8420646621152478,\n",
       " 0.790717377981866,\n",
       " 0.7487221160856373,\n",
       " 0.7351005180592886,\n",
       " 0.7871447554965818,\n",
       " 0.7782022011401301,\n",
       " 0.1834055404260181,\n",
       " 0.6357594206042351,\n",
       " 0.25480890877959256,\n",
       " 0.8300381150872266,\n",
       " 0.711879599640778,\n",
       " 0.7627430867677859,\n",
       " 0.8239310134408419,\n",
       " 0.7743986694628774,\n",
       " 0.8049308691726114,\n",
       " 0.68681015188685,\n",
       " 0.5224757585000503,\n",
       " 0.852538255413766,\n",
       " 0.8800524506555932,\n",
       " 0.5026695607009724,\n",
       " 0.7114074240777852,\n",
       " 0.4848372322781211,\n",
       " 0.8458406209229418,\n",
       " 0.7706638961822464,\n",
       " 0.7433514124719737,\n",
       " 0.7265609503184827,\n",
       " 0.7290379822935383,\n",
       " 0.5840370190984684,\n",
       " 0.8711534532082283,\n",
       " 0.7009226042707392,\n",
       " 0.8145266505554533,\n",
       " 0.7942209607435157,\n",
       " 0.763384661686371,\n",
       " 0.6065487491974039,\n",
       " 0.8482026783452746,\n",
       " 0.7587019471230758,\n",
       " 0.6169991744398408,\n",
       " 0.6761817593965089,\n",
       " 0.6963703949855787,\n",
       " 0.7485720013567235,\n",
       " 0.22572969304153212,\n",
       " 0.6910834854761593,\n",
       " 0.6511009235696917,\n",
       " 0.7382319647490562,\n",
       " 0.7204742943948013,\n",
       " 0.3673464221749317,\n",
       " 0.7068581856962064,\n",
       " 0.42560780678545274,\n",
       " 0.7695189705344666,\n",
       " 0.5688165980594823,\n",
       " 0.7365633557857381,\n",
       " 0.869786307533663,\n",
       " 0.8502553696281892,\n",
       " 0.8707665320979977,\n",
       " 0.7327852876186637,\n",
       " 0.7660947998998452,\n",
       " 0.7801982190456913,\n",
       " 0.6854152054046535,\n",
       " 0.6436475547912829,\n",
       " 0.7084263151061378,\n",
       " 0.7726489455285551,\n",
       " 0.46401185694610364,\n",
       " 0.7855745762909252,\n",
       " 0.5568074408714297,\n",
       " 0.71285145243542,\n",
       " 0.8320575944462968,\n",
       " 0.5156331260646184,\n",
       " 0.697139318418027,\n",
       " 0.5324526524952541,\n",
       " 0.7947268622032211,\n",
       " 0.6730298468686527,\n",
       " 0.7924056218854817,\n",
       " 0.6717120095538243,\n",
       " 0.706551848194699,\n",
       " 0.8438638439572018,\n",
       " 0.8098846495418831,\n",
       " 0.6482824438678257,\n",
       " 0.7940713012158208,\n",
       " 0.6811212029010139,\n",
       " 0.7275859424601153,\n",
       " 0.692710144012815,\n",
       " 0.6737091788381081,\n",
       " 0.5191008391130072,\n",
       " 0.5783541814178251,\n",
       " 0.5657358403135316,\n",
       " 0.7214298669085227,\n",
       " 0.8360212957643811,\n",
       " 0.21752289279423428,\n",
       " 0.5732314796258695,\n",
       " 0.7365837472112102,\n",
       " 0.5993224981060115,\n",
       " 0.80938619801187,\n",
       " 0.47122204174516596,\n",
       " 0.4202878244550419,\n",
       " 0.6188928689237553,\n",
       " 0.7462477089343061,\n",
       " 0.7777431541977982,\n",
       " 0.8397974471415647,\n",
       " 0.7978689882525641,\n",
       " 0.8388013190945559,\n",
       " 0.8451060487791798,\n",
       " 0.8055886808985261,\n",
       " 0.80875182142923,\n",
       " 0.8324296827135664,\n",
       " 0.8350051310824362,\n",
       " 0.31636708825691495,\n",
       " 0.21230201779130545,\n",
       " 0.7718158765935925,\n",
       " 0.8491799470298552,\n",
       " 0.6700442167433168,\n",
       " 0.8236973619563536,\n",
       " 0.7414825813633342,\n",
       " 0.7370101532477135,\n",
       " 0.5200283385359361,\n",
       " 0.7192122689997845,\n",
       " 0.6866038396504447,\n",
       " 0.673075963783071,\n",
       " 0.821811353328559,\n",
       " 0.8333613766990396,\n",
       " 0.8488111466276033,\n",
       " 0.7168090568955883,\n",
       " 0.8139822837635565,\n",
       " 0.7960618894605279,\n",
       " 0.6791450456735939,\n",
       " 0.4126555451342478,\n",
       " 0.657359875756762,\n",
       " 0.6918513393848448,\n",
       " 0.7643516054331215,\n",
       " 0.750237610172653,\n",
       " 0.6486255110592928,\n",
       " 0.7321826152183757,\n",
       " 0.802871912582933,\n",
       " 0.7846477055148338,\n",
       " 0.6330603644880938,\n",
       " 0.8618673459205187,\n",
       " 0.26445183382190335,\n",
       " 0.8440900627560187,\n",
       " 0.8012381597810888,\n",
       " 0.7296935115999115,\n",
       " 0.7672413138311861,\n",
       " 0.7525513120441141,\n",
       " 0.7300055186942315,\n",
       " 0.7615191265941835,\n",
       " 0.7784246810542604,\n",
       " 0.7487339868282502,\n",
       " 0.743663485810798,\n",
       " 0.5624936933252868,\n",
       " 0.8618492273690017,\n",
       " 0.7133986672378511,\n",
       " 0.8005850990857044,\n",
       " 0.8401169361201667,\n",
       " 0.7961799840916441,\n",
       " 0.7271954696023556,\n",
       " 0.8194381221116392,\n",
       " 0.7999050078372232,\n",
       " 0.8171231284576591,\n",
       " 0.6870342727698269,\n",
       " 0.6420344208053234,\n",
       " 0.317796510240599,\n",
       " 0.7778400088147824,\n",
       " 0.816663548515896,\n",
       " 0.5648726346456802,\n",
       " 0.8415478347963536,\n",
       " 0.724697366856708,\n",
       " 0.7601637872793248,\n",
       " 0.7018732831066821,\n",
       " 0.7714315730361413,\n",
       " 0.7912601128221292,\n",
       " 0.7463391161785085,\n",
       " 0.6111338602176258,\n",
       " 0.8400126620593408,\n",
       " 0.7459436766235079,\n",
       " 0.2308255721992398,\n",
       " 0.7881063283358923,\n",
       " 0.682560550471874,\n",
       " 0.8818693124701835,\n",
       " 0.6076751889242862,\n",
       " 0.769980366009745,\n",
       " 0.7662851893319056,\n",
       " 0.5691092646632477,\n",
       " 0.8229463561755028,\n",
       " 0.6217225310537849,\n",
       " 0.7989235958262105,\n",
       " 0.6912594483475271,\n",
       " 0.7870760839036478,\n",
       " 0.7952829715755912,\n",
       " 0.7663001743993059,\n",
       " 0.784147636419941,\n",
       " 0.263688541144647,\n",
       " 0.5703727264292671,\n",
       " 0.8140935437994882,\n",
       " 0.6819718489895049,\n",
       " 0.8244830215332621,\n",
       " 0.702530095729891,\n",
       " 0.7008054621890655,\n",
       " 0.8445798555071286,\n",
       " 0.810786932196843,\n",
       " 0.7478047391998969,\n",
       " 0.6848236146211701,\n",
       " 0.7071647488933502,\n",
       " 0.8506306945303977,\n",
       " 0.831469216145884,\n",
       " 0.857108583829944,\n",
       " 0.7054464418466232,\n",
       " 0.7471176320449384,\n",
       " 0.7670536785683795,\n",
       " 0.5881807217082607,\n",
       " 0.6926731234118629,\n",
       " 0.7329824546117325,\n",
       " 0.7160380647913275,\n",
       " 0.8562365994670459,\n",
       " 0.8489389615576827,\n",
       " 0.7619010329565352,\n",
       " 0.6952789414765134,\n",
       " 0.8736249729031167,\n",
       " 0.8159864373133692,\n",
       " 0.7613492286436582,\n",
       " 0.7646440082064548,\n",
       " 0.6526536077109922,\n",
       " 0.8298166972017285,\n",
       " 0.8514816148326757,\n",
       " 0.6826644130851226,\n",
       " 0.685611528193634,\n",
       " 0.38593946629445625,\n",
       " 0.7574994581322975,\n",
       " 0.6778518800447446,\n",
       " 0.31289959763011166,\n",
       " 0.7719008685872719,\n",
       " 0.6660054329926915,\n",
       " 0.7919606214427839,\n",
       " 0.8120973019298919,\n",
       " 0.28505555709667574,\n",
       " 0.803000377437515,\n",
       " 0.8470912459103674,\n",
       " 0.7510347901386707,\n",
       " 0.3586411716895533,\n",
       " 0.66944632561774,\n",
       " 0.8259856187775821,\n",
       " 0.8282575176350543,\n",
       " 0.7297090155035776,\n",
       " 0.635197870626183,\n",
       " 0.23637897960912904,\n",
       " 0.2964880262040329,\n",
       " 0.8121682929779054,\n",
       " 0.6802071192958544,\n",
       " 0.7460460060569826,\n",
       " 0.35375298766015684,\n",
       " 0.66415099112935,\n",
       " 0.6316409018278533,\n",
       " 0.7682831175024138,\n",
       " 0.7816483729373079,\n",
       " 0.6184779542143927,\n",
       " 0.4815526557099124,\n",
       " 0.5179630017594086,\n",
       " 0.6048080274673967,\n",
       " 0.7872146270983978,\n",
       " 0.7002849428192365,\n",
       " 0.287518209228019,\n",
       " 0.7746728744831554,\n",
       " 0.46434568584689795,\n",
       " 0.6534968665674986,\n",
       " 0.7299523937299183,\n",
       " 0.20817180555634762,\n",
       " 0.4908124871359063,\n",
       " 0.6633421308156834,\n",
       " 0.7792856568299312,\n",
       " 0.6942177409813088,\n",
       " 0.8086784058462008,\n",
       " 0.5306100586750733,\n",
       " 0.8405781339123576,\n",
       " 0.7637598108209137,\n",
       " 0.7338511652890967,\n",
       " 0.6231452650522945,\n",
       " 0.3181655214524333,\n",
       " 0.2971521652648361,\n",
       " 0.36910097411086523,\n",
       " 0.5710064654291274,\n",
       " 0.7697548793081052,\n",
       " 0.3078668798903031,\n",
       " 0.5888102589204457,\n",
       " 0.7583441843855042,\n",
       " 0.7081274012069256,\n",
       " 0.7590446172882657,\n",
       " 0.47669636153773237,\n",
       " 0.7682294809689689,\n",
       " 0.8060770528515852,\n",
       " 0.7613152729832903,\n",
       " 0.6908650678909826,\n",
       " 0.6997221612370369,\n",
       " 0.7455721930326749,\n",
       " 0.6834495884794866,\n",
       " 0.3061251534988067,\n",
       " 0.7614057187124369,\n",
       " 0.6041854791675303,\n",
       " 0.7017456603404625,\n",
       " 0.6565410976576526,\n",
       " 0.6281336983208431,\n",
       " 0.6853645209297596,\n",
       " 0.7944985964571437,\n",
       " 0.7482604359865647,\n",
       " 0.6591656987324234,\n",
       " 0.5641769790672044,\n",
       " 0.16793106566915184,\n",
       " 0.7528818835188315,\n",
       " 0.7977597844130893,\n",
       " 0.45653753270294234,\n",
       " 0.5671519722278274,\n",
       " 0.5958571421979414,\n",
       " 0.8149038962674483,\n",
       " 0.8234045711365093,\n",
       " 0.6010739047189112,\n",
       " 0.6294627542975552,\n",
       " 0.8482877946352133,\n",
       " 0.4976663268174139,\n",
       " 0.7731919924415719,\n",
       " 0.7665684133974707,\n",
       " 0.6861373101698484,\n",
       " 0.4209354113414283,\n",
       " 0.8120611472139819,\n",
       " 0.6931914002377679,\n",
       " 0.7298441667382951,\n",
       " 0.6745805689763601,\n",
       " 0.8264097023960907,\n",
       " 0.7502832258751703,\n",
       " 0.7642280990522373,\n",
       " 0.8821592443324157,\n",
       " 0.7568512293862965,\n",
       " 0.7768318720699421,\n",
       " 0.6471617278414823,\n",
       " 0.6940315894267929,\n",
       " 0.7583081103121954,\n",
       " 0.631601038674433,\n",
       " 0.8244692094259305,\n",
       " 0.44215894659266014,\n",
       " 0.7680539535866634,\n",
       " 0.239784210651953,\n",
       " 0.7015180294286614,\n",
       " 0.44096607672395055,\n",
       " 0.45526032442737513,\n",
       " 0.5723745548563136,\n",
       " 0.7785845786621381,\n",
       " 0.42740682397622765,\n",
       " 0.807081297931599,\n",
       " 0.5466312065433448,\n",
       " 0.7283988272999249,\n",
       " 0.8611700885399958,\n",
       " 0.8154008819290249,\n",
       " 0.5680203864173315,\n",
       " 0.21101848401980927,\n",
       " 0.8639965443583432,\n",
       " 0.4909683279594677,\n",
       " 0.7815986479709006,\n",
       " 0.8667207099163878,\n",
       " 0.7385887551598961,\n",
       " 0.848729435685892,\n",
       " 0.733011088905594,\n",
       " 0.6575911026752043,\n",
       " 0.4522713581405975,\n",
       " 0.799403733663854,\n",
       " 0.8413876594737308,\n",
       " 0.8484749593860558,\n",
       " 0.6325379385888787,\n",
       " 0.8283767331595152,\n",
       " 0.6557597517552421,\n",
       " 0.23782790156815312,\n",
       " 0.5512632912039418,\n",
       " 0.8208493543123172,\n",
       " 0.6021468823808426,\n",
       " 0.7525681302626799,\n",
       " 0.792794806667349,\n",
       " 0.8720946489514737,\n",
       " 0.8398293895124406,\n",
       " 0.7949582327807985,\n",
       " 0.5924722423633974,\n",
       " 0.7407370845349998,\n",
       " 0.7257799412104445,\n",
       " 0.6395940508411201,\n",
       " 0.5756530186449139,\n",
       " 0.7235760269461098,\n",
       " 0.6996963430949096,\n",
       " 0.8222695348040636,\n",
       " 0.860811084491164,\n",
       " 0.8256376057618166,\n",
       " 0.8263710979427566,\n",
       " 0.25957901435155356,\n",
       " 0.43961066151531564,\n",
       " 0.5515734497586965,\n",
       " 0.630380796371277,\n",
       " 0.5846014542707095,\n",
       " 0.7958308184873258,\n",
       " 0.8175578783280675,\n",
       " 0.7937760539772993,\n",
       " 0.6693810784319286,\n",
       " 0.6679729494632284,\n",
       " 0.7607626661641212,\n",
       " 0.5335800672884344,\n",
       " 0.7184897027418863,\n",
       " 0.5445042506958552,\n",
       " 0.6550530167147799,\n",
       " 0.5773014085256825,\n",
       " 0.6169616929195184,\n",
       " 0.8048328360145752,\n",
       " 0.2656584673390225,\n",
       " 0.5701284036584059,\n",
       " 0.6798448661805812,\n",
       " 0.7965221972142823,\n",
       " 0.83999038785118,\n",
       " 0.6962424423732885,\n",
       " 0.31990512879517236,\n",
       " 0.7594136648539275,\n",
       " 0.6790303853307308,\n",
       " 0.2482222939529024,\n",
       " 0.788590165809905,\n",
       " 0.8243505600897217,\n",
       " 0.26024464587922685,\n",
       " 0.8489935380889767,\n",
       " 0.33221562004775623,\n",
       " 0.8482030158726693,\n",
       " 0.41065707993808104,\n",
       " 0.3902394082184178,\n",
       " 0.8586766559324047,\n",
       " 0.7465162535243763,\n",
       " 0.7485766033568115,\n",
       " 0.5247380499442816,\n",
       " 0.7577438006598594,\n",
       " 0.6725590936050153,\n",
       " 0.8167175205091857,\n",
       " 0.7277814093205497,\n",
       " 0.7075789440566075,\n",
       " 0.6812980079409127,\n",
       " 0.8311223422937126,\n",
       " 0.83703594797842,\n",
       " 0.7440655517171061,\n",
       " 0.7009124997742754,\n",
       " 0.7659990346967733,\n",
       " 0.6090250584834039,\n",
       " 0.2121478997972711,\n",
       " 0.7251212553740348,\n",
       " 0.3768345782530292,\n",
       " 0.596410658799119,\n",
       " 0.6877546449651085,\n",
       " 0.687684358232774,\n",
       " 0.5821790577563766,\n",
       " 0.7673417423400052,\n",
       " 0.6560710982198746,\n",
       " 0.6920100584747172,\n",
       " 0.7474632014606097,\n",
       " 0.7803802408653416,\n",
       " 0.6728664518683477,\n",
       " 0.5729752636983028,\n",
       " 0.7094451436240208,\n",
       " 0.7666757070294142,\n",
       " 0.8045932097895042,\n",
       " 0.8292388066083743,\n",
       " 0.6873311400699028,\n",
       " 0.7305830167519302,\n",
       " 0.6323075374481913,\n",
       " 0.786325556315151,\n",
       " 0.5025244582155134,\n",
       " 0.7767982210895474,\n",
       " 0.8485762227136663,\n",
       " 0.8475132328419246,\n",
       " 0.6980220671476826,\n",
       " 0.7836825320595932,\n",
       " 0.7858001596506506,\n",
       " 0.5807383183942063,\n",
       " 0.7590561275271184,\n",
       " 0.8525756097603671,\n",
       " 0.6603725146550348,\n",
       " 0.7896166408448829,\n",
       " 0.660528403578372,\n",
       " 0.7447173986126279,\n",
       " 0.4958377708247739,\n",
       " 0.7662297930451758,\n",
       " 0.7775751761421997,\n",
       " 0.7780522336405674,\n",
       " 0.7208394979645995,\n",
       " 0.8047423361292757,\n",
       " 0.8350064759535555,\n",
       " 0.8409054004630357,\n",
       " 0.6415343959003174,\n",
       " 0.8436327461031593,\n",
       " 0.7572232313690709,\n",
       " 0.7819592876150859,\n",
       " 0.7475492668973013,\n",
       " 0.6132577975732364,\n",
       " 0.26450363846650665,\n",
       " 0.6097610301421522,\n",
       " 0.6924494706289878,\n",
       " 0.7918548642505998,\n",
       " 0.6480434050832011,\n",
       " 0.3289388056627918,\n",
       " 0.7096079990205449,\n",
       " 0.7612222909678014,\n",
       " 0.3744400945662781,\n",
       " 0.7553421924245219,\n",
       " 0.6946023334234654,\n",
       " 0.5246460669423959,\n",
       " 0.76809615423472,\n",
       " 0.26651120226269526,\n",
       " 0.6854714416402273,\n",
       " 0.8328926239934304,\n",
       " 0.7469654113582266,\n",
       " 0.7573893469178206,\n",
       " 0.7105448853857839,\n",
       " 0.1794009875499014,\n",
       " 0.8524893519464051,\n",
       " 0.7495795703135059,\n",
       " 0.8483650041079298,\n",
       " 0.7381304070443905,\n",
       " 0.7698223546682611,\n",
       " 0.8540025970991306,\n",
       " 0.8832050660395191,\n",
       " 0.8334371463988063,\n",
       " 0.8031241939799885,\n",
       " 0.6623788385326551,\n",
       " 0.7462197728186258,\n",
       " 0.8624359126483189,\n",
       " 0.7711074956959599,\n",
       " 0.8683858155679526,\n",
       " 0.7866463767197023,\n",
       " 0.5894571101399769,\n",
       " 0.5439978246592863,\n",
       " 0.8404989823416863,\n",
       " 0.724075370133789,\n",
       " 0.8007254198950343,\n",
       " 0.8255426736725413,\n",
       " 0.8210989125000284,\n",
       " 0.811139814898601,\n",
       " 0.7095225031699263,\n",
       " 0.33048345664388973,\n",
       " 0.7080913056916095,\n",
       " 0.7766615923739817,\n",
       " 0.7350081002121129,\n",
       " 0.7269459979557621,\n",
       " 0.8118096390305117,\n",
       " 0.824513120325865,\n",
       " 0.7159972881780113,\n",
       " 0.5854756480605028,\n",
       " 0.8315037304712636,\n",
       " 0.8134855706055633,\n",
       " 0.7866916872905079,\n",
       " 0.7390283559891574,\n",
       " 0.7275438819308574,\n",
       " 0.8501404017507322,\n",
       " 0.8178155438660433,\n",
       " 0.8535162499149558,\n",
       " 0.8261483275497183,\n",
       " 0.6833210983875097,\n",
       " 0.6774715451119375,\n",
       " 0.853967360009884,\n",
       " 0.8185522890537388,\n",
       " 0.6157534847903018,\n",
       " 0.8107309896411086,\n",
       " 0.7543394572281491,\n",
       " 0.802354797680894,\n",
       " 0.7627392170461457,\n",
       " 0.5451581927442078,\n",
       " 0.7692585996974867,\n",
       " 0.8252313072129663,\n",
       " 0.8060154410643673,\n",
       " 0.6176322824940379,\n",
       " 0.8058992978987033,\n",
       " 0.39656439789575537,\n",
       " 0.751695712622723,\n",
       " 0.6529299472555196,\n",
       " 0.5696473483902437,\n",
       " 0.560367324974246,\n",
       " 0.8189274048641373,\n",
       " 0.8602077189174757,\n",
       " 0.6293553559847888,\n",
       " 0.8618125013162281,\n",
       " 0.7920121985202598,\n",
       " 0.6409078488036323,\n",
       " 0.8138592509199194,\n",
       " 0.7487099234978613,\n",
       " 0.6919209143194295,\n",
       " 0.37388692845926935,\n",
       " 0.6299363699404651,\n",
       " 0.5131023643816919,\n",
       " 0.8005614815408926,\n",
       " 0.7860763364285029,\n",
       " 0.8531822098599094,\n",
       " 0.690370766230525,\n",
       " 0.776019263749563,\n",
       " 0.7806895933849024,\n",
       " 0.7548842366537212,\n",
       " 0.7094403853571074,\n",
       " 0.7703847998238936,\n",
       " 0.837710590170263,\n",
       " 0.6235902366558707,\n",
       " 0.5766106791190978,\n",
       " 0.5957275867063457,\n",
       " 0.12532358766284105,\n",
       " 0.7767346103719396,\n",
       " 0.6905641940139459,\n",
       " 0.7525199720226227,\n",
       " 0.6861934353561393,\n",
       " 0.8149540242368868,\n",
       " 0.8090345016159587,\n",
       " 0.7194167458276813,\n",
       " 0.8290386225137821,\n",
       " 0.6940192607110173,\n",
       " 0.25903175806634277,\n",
       " 0.8416938456546168,\n",
       " 0.630174740777659,\n",
       " 0.6930068268338884,\n",
       " 0.3574778232047833,\n",
       " 0.3938055078423721,\n",
       " 0.6608568841260795,\n",
       " 0.747353217396333,\n",
       " 0.7133858389037818,\n",
       " 0.7211121287053102,\n",
       " 0.6950321263849067,\n",
       " 0.7244395293267646,\n",
       " 0.8162205608759283,\n",
       " 0.6545000470243448,\n",
       " 0.8153786786420728,\n",
       " 0.7929409232282053,\n",
       " 0.7846862031279901,\n",
       " 0.8482636100934471,\n",
       " 0.7244356257305259,\n",
       " 0.23992142739173986,\n",
       " 0.7339302657172707,\n",
       " 0.2546692457702672,\n",
       " 0.5486869609916152,\n",
       " 0.7046899251587716,\n",
       " 0.7961210411304358,\n",
       " 0.7103074317124544,\n",
       " 0.6280042119608084,\n",
       " 0.6831958138505901,\n",
       " 0.6614560127549769,\n",
       " 0.8654406982724097,\n",
       " 0.4077029100152137,\n",
       " 0.6570082208513043,\n",
       " 0.8243963315162465,\n",
       " 0.4508431486981597,\n",
       " 0.6765100958684349,\n",
       " 0.6174082641330503,\n",
       " 0.581991824138787,\n",
       " 0.40944496141331516,\n",
       " 0.24940274362654247,\n",
       " 0.6750138729836636,\n",
       " 0.6261981816608215,\n",
       " 0.7318048726128383,\n",
       " 0.7999579980130257,\n",
       " 0.7586230463470228,\n",
       " 0.7804317314668503,\n",
       " 0.8296864639201545,\n",
       " 0.5664530154430899,\n",
       " 0.5597683705393338,\n",
       " 0.7480829520028026,\n",
       " 0.7870951451859846,\n",
       " 0.6383654485219538,\n",
       " 0.7490907625944647,\n",
       " 0.835530604173635,\n",
       " 0.8591587741271245,\n",
       " 0.6430927637533655,\n",
       " 0.6599603610517634,\n",
       " 0.8202649622106364,\n",
       " 0.17372674811251496,\n",
       " 0.6829426701460605,\n",
       " 0.7824303933365725,\n",
       " 0.7421814622982139,\n",
       " 0.7013315383181192,\n",
       " 0.8216393040760176,\n",
       " 0.34327518752361835,\n",
       " 0.7457857513822822,\n",
       " 0.6442902729327303,\n",
       " 0.4532745920328602,\n",
       " 0.7334429742812384,\n",
       " 0.7552056031628966,\n",
       " 0.6927001130903693,\n",
       " 0.7810193364314891,\n",
       " 0.8277311584043551,\n",
       " 0.6545916344159957,\n",
       " 0.6621060205642751,\n",
       " 0.8415290047080902,\n",
       " 0.8174846010576498,\n",
       " 0.17706243962946078,\n",
       " 0.7630389722751678,\n",
       " 0.30943885662268544,\n",
       " 0.5859927981734784,\n",
       " 0.8373484534065057,\n",
       " 0.7360983312343676,\n",
       " 0.17123304042849208,\n",
       " 0.7297831445291777,\n",
       " 0.6963668572169549,\n",
       " 0.776072373413374,\n",
       " 0.7113023589227883,\n",
       " 0.7265900728024836,\n",
       " 0.6792254834877521,\n",
       " 0.8537515065554739,\n",
       " 0.784460988393972,\n",
       " 0.5735599137531832,\n",
       " 0.7882142239095365,\n",
       " 0.8130333772229167,\n",
       " 0.8172221079145011,\n",
       " 0.7593989212728457,\n",
       " 0.6108084718368262,\n",
       " 0.552058947188418,\n",
       " 0.6682400614169769,\n",
       " 0.7883682163802103,\n",
       " 0.580234180259473,\n",
       " 0.6777776773852305,\n",
       " 0.7807213766101223,\n",
       " 0.7468181126523086,\n",
       " 0.7153101960955667,\n",
       " 0.7614890687591492,\n",
       " 0.4879905532565514,\n",
       " 0.7248041699331869,\n",
       " 0.7833472500779628,\n",
       " 0.8325455276385029,\n",
       " 0.7847378238826557,\n",
       " 0.7728275315817604,\n",
       " 0.6104610105852434,\n",
       " 0.6844763009848155,\n",
       " 0.5892972712465167,\n",
       " 0.734060565125788,\n",
       " 0.5760704343429001,\n",
       " 0.8265626312234099,\n",
       " 0.7436572097678408,\n",
       " 0.7842434614035526,\n",
       " 0.6731568729807998,\n",
       " 0.7895549023099466,\n",
       " 0.7642639757049231,\n",
       " 0.63537681252606,\n",
       " 0.8632302923821151,\n",
       " 0.7532410505485133,\n",
       " 0.721117896258978,\n",
       " 0.7822284003561365,\n",
       " 0.7382381652386188,\n",
       " 0.7734036165219038,\n",
       " 0.7744749463718626,\n",
       " 0.8571425985740587,\n",
       " 0.7391264159567341,\n",
       " 0.8100788892359551,\n",
       " 0.737181325249551,\n",
       " 0.8195517265797155,\n",
       " 0.8406825183910932,\n",
       " 0.46745305971191925,\n",
       " 0.8686748825985161,\n",
       " 0.7311498198995379,\n",
       " 0.7008500249557305,\n",
       " 0.8068670077148653,\n",
       " 0.850803932050284,\n",
       " 0.5542240794851846,\n",
       " 0.7333155245383344,\n",
       " 0.8289965545073956,\n",
       " 0.7409343707935404,\n",
       " 0.6227229904134307,\n",
       " 0.6489891339419499,\n",
       " 0.6978064469599801,\n",
       " 0.8221373795528786,\n",
       " 0.6825605612147391,\n",
       " 0.7204503691993631,\n",
       " 0.7915177132482749,\n",
       " 0.75854620421863,\n",
       " 0.7219824886090369,\n",
       " 0.5591963006042878,\n",
       " 0.8680933363394193,\n",
       " 0.5345509580525404,\n",
       " 0.8065155556992366,\n",
       " 0.700224162804784,\n",
       " 0.6408832421045046,\n",
       " 0.5827832625813308,\n",
       " 0.8293957143444817,\n",
       " 0.6348179126271439,\n",
       " 0.8412093670180774,\n",
       " 0.7249542116121422,\n",
       " 0.6942367369237524,\n",
       " 0.7062839050346938,\n",
       " 0.7236518878495554,\n",
       " 0.7915553074467496,\n",
       " 0.8148154668963564,\n",
       " 0.8817010385025795,\n",
       " 0.6725490933300823,\n",
       " 0.7097664785424382,\n",
       " 0.6402107271669085,\n",
       " 0.8609374412429119,\n",
       " 0.8376561933903132,\n",
       " 0.591995754756578,\n",
       " 0.7458624676580946,\n",
       " 0.7678342052084696,\n",
       " 0.8042708028877606,\n",
       " ...]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = pd.DataFrame({'urlid': data_test['urlid'],'label': rel})\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='out123.csv')  \n",
    "xx.to_csv('he.zip', index=False,\n",
    "          compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = data[['boilerplate', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boilerplate = main_data['boilerplate']\n",
    "\n",
    "dicts = {\n",
    "    'title' : [],\n",
    "    'body' : [],\n",
    "    'url' : []\n",
    "}\n",
    "for i in range(len(boilerplate)):\n",
    "    temp = json.loads(boilerplate[i])\n",
    "    for j in dicts.keys():\n",
    "        dicts[j].append(temp.get(j, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batte...</td>\n",
       "      <td>A sign stands outside the International Busine...</td>\n",
       "      <td>bloomberg news 2010 12 23 ibm predicts hologra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Fully Electronic Futuristic Starting Gun T...</td>\n",
       "      <td>And that can be carried on a plane without the...</td>\n",
       "      <td>popsci technology article 2012 07 electronic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fruits that Fight the Flu fruits that fight th...</td>\n",
       "      <td>Apples The most popular source of antioxidants...</td>\n",
       "      <td>menshealth health flu fighting fruits cm mmc F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Foolproof Tips for Better Sleep</td>\n",
       "      <td>There was a period in my life when I had a lot...</td>\n",
       "      <td>dumblittleman 2007 12 10 foolproof tips for be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 50 Coolest Jerseys You Didn t Know Existed...</td>\n",
       "      <td>Jersey sales is a curious business Whether you...</td>\n",
       "      <td>bleacherreport articles 1205138 the 50 coolest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>Kno Raises 46 Million More To Build Most Power...</td>\n",
       "      <td>Marc Andreessen is normally enthusiastic about...</td>\n",
       "      <td>techcrunch 2010 09 08 kno raises 46 million mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>Why I Miss College</td>\n",
       "      <td>Mar 30 2009 I d like to congratulate Jane on h...</td>\n",
       "      <td>uncoached category why i miss college</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>Sweet Potatoes Eat This Not That  i'm eating t...</td>\n",
       "      <td>They re loaded with vitamin C which smoothes o...</td>\n",
       "      <td>eatthis menshealth slide sweet potatoes slides...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>Naturally Ella</td>\n",
       "      <td></td>\n",
       "      <td>naturallyella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>Esti Ginzburg Swimsuit by Letarte by Lisa Cabr...</td>\n",
       "      <td>Esti Ginzburg 20 is a native of Tel Aviv Israe...</td>\n",
       "      <td>sportsillustrated cnn 2011 swimsuit models est...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7395 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     IBM Sees Holographic Calls Air Breathing Batte...   \n",
       "1     The Fully Electronic Futuristic Starting Gun T...   \n",
       "2     Fruits that Fight the Flu fruits that fight th...   \n",
       "3                   10 Foolproof Tips for Better Sleep    \n",
       "4     The 50 Coolest Jerseys You Didn t Know Existed...   \n",
       "...                                                 ...   \n",
       "7390  Kno Raises 46 Million More To Build Most Power...   \n",
       "7391                                Why I Miss College    \n",
       "7392  Sweet Potatoes Eat This Not That  i'm eating t...   \n",
       "7393                                    Naturally Ella    \n",
       "7394  Esti Ginzburg Swimsuit by Letarte by Lisa Cabr...   \n",
       "\n",
       "                                                   body  \\\n",
       "0     A sign stands outside the International Busine...   \n",
       "1     And that can be carried on a plane without the...   \n",
       "2     Apples The most popular source of antioxidants...   \n",
       "3     There was a period in my life when I had a lot...   \n",
       "4     Jersey sales is a curious business Whether you...   \n",
       "...                                                 ...   \n",
       "7390  Marc Andreessen is normally enthusiastic about...   \n",
       "7391  Mar 30 2009 I d like to congratulate Jane on h...   \n",
       "7392  They re loaded with vitamin C which smoothes o...   \n",
       "7393                                                      \n",
       "7394  Esti Ginzburg 20 is a native of Tel Aviv Israe...   \n",
       "\n",
       "                                                    url  \n",
       "0     bloomberg news 2010 12 23 ibm predicts hologra...  \n",
       "1     popsci technology article 2012 07 electronic f...  \n",
       "2     menshealth health flu fighting fruits cm mmc F...  \n",
       "3     dumblittleman 2007 12 10 foolproof tips for be...  \n",
       "4     bleacherreport articles 1205138 the 50 coolest...  \n",
       "...                                                 ...  \n",
       "7390  techcrunch 2010 09 08 kno raises 46 million mo...  \n",
       "7391              uncoached category why i miss college  \n",
       "7392  eatthis menshealth slide sweet potatoes slides...  \n",
       "7393                                      naturallyella  \n",
       "7394  sportsillustrated cnn 2011 swimsuit models est...  \n",
       "\n",
       "[7395 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = pd.DataFrame()\n",
    "text_data['title'] = dicts['title']\n",
    "text_data['body'] = dicts['body']\n",
    "text_data['url'] = dicts['url']\n",
    "\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_text_data = text_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNanAndNone(data_):\n",
    "    fea = ['title', 'body', 'url']\n",
    "    for name in fea:\n",
    "        data_[name].fillna(\" \", inplace= True)\n",
    "#         for i, text in enumerate(data_[name]):\n",
    "#             if len(text) == 1:\n",
    "#                 data_[name][i] = \"-1\"\n",
    "    return data_\n",
    "\n",
    "ano_text_data = fillNanAndNone(ano_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batte...</td>\n",
       "      <td>A sign stands outside the International Busine...</td>\n",
       "      <td>bloomberg news 2010 12 23 ibm predicts hologra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Fully Electronic Futuristic Starting Gun T...</td>\n",
       "      <td>And that can be carried on a plane without the...</td>\n",
       "      <td>popsci technology article 2012 07 electronic f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fruits that Fight the Flu fruits that fight th...</td>\n",
       "      <td>Apples The most popular source of antioxidants...</td>\n",
       "      <td>menshealth health flu fighting fruits cm mmc F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Foolproof Tips for Better Sleep</td>\n",
       "      <td>There was a period in my life when I had a lot...</td>\n",
       "      <td>dumblittleman 2007 12 10 foolproof tips for be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 50 Coolest Jerseys You Didn t Know Existed...</td>\n",
       "      <td>Jersey sales is a curious business Whether you...</td>\n",
       "      <td>bleacherreport articles 1205138 the 50 coolest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Genital Herpes Treatment</td>\n",
       "      <td>Genital herpes is caused by herpes simplex vir...</td>\n",
       "      <td>conveniencemedical genital herpes home php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fashion lane American Wild Child</td>\n",
       "      <td>Our favorite summer holiday is just around the...</td>\n",
       "      <td>gofashionlane blogspot tw 2012 06 american wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Racing For Recovery by Dean Johnson racing for...</td>\n",
       "      <td>Racing For Recovery is the growing idea that d...</td>\n",
       "      <td>insidershealth article racing for recovery 3471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valet The Handbook 31 Days 31 days</td>\n",
       "      <td>Resolutions are for suckers Instead of swearin...</td>\n",
       "      <td>valetmag the handbook features 31 days index p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cookies and Cream Brownies How Sweet It Is</td>\n",
       "      <td>More brownies It seems that I can t get throug...</td>\n",
       "      <td>howsweeteats 2010 03 24 cookies and cream brow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Business Financial News Breaking US Internatio...</td>\n",
       "      <td>Faced with a stream of financial scandals the ...</td>\n",
       "      <td>reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A Tip of the Cap to The Greatest Iron Man of T...</td>\n",
       "      <td>As you surely know by now Brett Favre s NFL re...</td>\n",
       "      <td>midwestsportsfans 2010 12 photo story the grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9 Foods That Trash Your Teeth</td>\n",
       "      <td>There are the 700 different types of germs in ...</td>\n",
       "      <td>ivillage our dirty mouths 4 b 188305 iv NPA 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>thedailygreen print this healthy eating eat sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>French Onion Steaks with Red Wine Sauce french...</td>\n",
       "      <td>Really this is just an excuse to get drunk Or ...</td>\n",
       "      <td>phillyburbs blogs type a kitchen french onion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Izabel Goulart Swimsuit by Kikidoll 2012 Sport...</td>\n",
       "      <td>TM 2012 Turner Broadcasting System Inc A Time ...</td>\n",
       "      <td>sportsillustrated cnn 2012 swimsuit models iza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Liquid Mountaineering The Awesomer</td>\n",
       "      <td>Link We re pretty skeptical about walking on w...</td>\n",
       "      <td>theawesomer liquid mountaineering 38622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>The annual Chap Olympiad described as a celebr...</td>\n",
       "      <td>guardian co uk fashion gallery 2012 jul 08 gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Grilled Peaches Sugarcrafter</td>\n",
       "      <td>June 6 2011 Print E mail Filed under grilled p...</td>\n",
       "      <td>sugarcrafter 2011 06 06 grilled peaches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How to Make Your Home Healthier A Room by Room...</td>\n",
       "      <td>Studies show one in three shower heads are con...</td>\n",
       "      <td>ivillage bathroom degrunge your shower head sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Olympic Soccer Babe Alex Morgan Medal Winning ...</td>\n",
       "      <td>Olympic Soccer BabeMedal Winning Bikini Body T...</td>\n",
       "      <td>tmz 2012 12 20 olympic soccer alex morgan biki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BBC Food Recipes Blueberry and lemon traybake</td>\n",
       "      <td>this fruity traybake is so good, you won't be...</td>\n",
       "      <td>bbc co uk food recipes blueberry and lemon 090...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Quit Smoking Counter Online counter that measu...</td>\n",
       "      <td>Loading After You Quit Smoking The Healing Beg...</td>\n",
       "      <td>quitcounter quitsmoking php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Original techniques to tie your shoe laces</td>\n",
       "      <td>http www damascus online com guide p 4 8734 ie...</td>\n",
       "      <td>monicel info 2008 08 03 original techniques to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>blogs babble family kitchen 2011 04 06 ultimat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Best College Football Fan Sign Ever Alabama Fan</td>\n",
       "      <td>Want a prime example of just how intertwined t...</td>\n",
       "      <td>midwestsportsfans 2010 10 early 2010 nominee f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Breaking News Blog</td>\n",
       "      <td>Contact Empty List Empty List Empty List Katie...</td>\n",
       "      <td>breakingnewsblog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The Alton Brown Flower Pot Smoker</td>\n",
       "      <td>Friends built the Alton Brown flower pot smoke...</td>\n",
       "      <td>naffziger blog 2008 07 05 the alton brown flow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Supermodels show off their bikini bods Humor</td>\n",
       "      <td>May 1222 Miranda Kerr Irina Shayk Behati Prins...</td>\n",
       "      <td>humor cool been wp supermodels show off their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Genevieve Morton Swimsuit by Tyler Rose Swimwe...</td>\n",
       "      <td>Genevieve Morton 24 hails from Benoni South Af...</td>\n",
       "      <td>sportsillustrated cnn 2011 swimsuit models gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Homemade Bagels Tammy s Recipes</td>\n",
       "      <td>I m a very unskilled baker in fact I think I c...</td>\n",
       "      <td>tammysrecipes homemade bagels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Whole Wheat Chocolate Chai Muffins Savvy Eats</td>\n",
       "      <td>I think I subconsciously sabotaged myself Two ...</td>\n",
       "      <td>savvyeat whole wheat chocolate chai muffins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ten ways to be Fabulous</td>\n",
       "      <td>One of my favorite bloggers Ashe Mischief over...</td>\n",
       "      <td>chicandcharming 2008 01 ten ways to be fabulou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Asian Orange Chicken Recipe Allrecipes com asi...</td>\n",
       "      <td>enjoy delicious citrus chicken marinated in l...</td>\n",
       "      <td>allrecipes Recipe Asian Orange Chicken Detail ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Chocolate Bread Pudding with Walnuts and Choco...</td>\n",
       "      <td>Toss bread cubes 1 2 cup chocolate chips and t...</td>\n",
       "      <td>epicurious articlesguides holidays valentinesd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NerdsMagazine Everything About Android</td>\n",
       "      <td>If you are from your Windows default look woul...</td>\n",
       "      <td>nerdsmagazine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Microwave Popcorn Minus the Ripoff microwave p...</td>\n",
       "      <td>May 6 2008 2 49 pm By MARK BITTMAN Somehow I v...</td>\n",
       "      <td>bitten blogs nytimes 2008 05 06 microwave popc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pogo Shoes CollegeHumor Video pogo shoes</td>\n",
       "      <td>Drink Thief My room mate has this annoying hab...</td>\n",
       "      <td>collegehumor video 1806201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Creamy Raspberry Orange Popsicles PETA org cre...</td>\n",
       "      <td>creamy raspberry-orange popsicles are a refre...</td>\n",
       "      <td>peta org living vegetarian living creamy raspb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Doctors Strike Mutating Bacteria In Teen Acne ...</td>\n",
       "      <td>Charles Bowman University of Pittsburgh A tiny...</td>\n",
       "      <td>npr org blogs health 2012 10 15 162821580 doct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The bottled water fad UK</td>\n",
       "      <td>Part 1 Introduction One of the most profitable...</td>\n",
       "      <td>second opinions co uk bottle html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>canarygirl com I am a Pickle Ho And I think I ...</td>\n",
       "      <td>Holy mother of mothers folks I don t know if y...</td>\n",
       "      <td>canarygirl p 302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Photo 1 Festive Funky Holiday Nail Art DIYs fe...</td>\n",
       "      <td>Festive Funky Holiday Nail Art DIYs Snowfall G...</td>\n",
       "      <td>refinery29 holiday nail art diy slideshow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>11 Power Foods for Lower Cholesterol High Chol...</td>\n",
       "      <td>Oils 6 image While butter and other solid fats...</td>\n",
       "      <td>everydayhealth high cholesterol pictures power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Alyssa Miller Swimsuit by Charlie by Matthew Z...</td>\n",
       "      <td>Alyssa Miller 20 was born in Los Angeles Calif...</td>\n",
       "      <td>sportsillustrated cnn 2011 swimsuit action aly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Breaking News Headlines</td>\n",
       "      <td>AMDB10K Where News Research Rewards News We Se...</td>\n",
       "      <td>amdb10k breaking news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Twenty1F twenty1f</td>\n",
       "      <td>Jul23 Francesca Lanzavecchia born in Pavia Ita...</td>\n",
       "      <td>twenty1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Apple Dumplings II Recipe Allrecipes com apple...</td>\n",
       "      <td>whole apples are wrapped in homemade pastry, ...</td>\n",
       "      <td>allrecipes Recipe Apple Dumplings II 2 Detail ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>300lbs American footballer Danous Estenor lift...</td>\n",
       "      <td>By Mark DuellLast updated at 2 10 AM on 25th J...</td>\n",
       "      <td>dailymail co uk news article 2007972 300lbs Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Pro Athletes Who Went Broke pro athletes who w...</td>\n",
       "      <td>rate or flagPin It By HypersapienWhat Happened...</td>\n",
       "      <td>hypersapien hubpages hubfc hub Pro Athletes Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Fashion Blog Baur Most Expensive Jeans in the ...</td>\n",
       "      <td>08 11 2010 Undoubtedly the most famous of Levi...</td>\n",
       "      <td>baur de content tunk categories jeans most exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Best S mores Recipes Ever YummyMummyClub ca</td>\n",
       "      <td>Nothing says summer fun like cooking marshmall...</td>\n",
       "      <td>yummymummyclub ca food recipes best smores rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>National Sleep Foundation Information on Sleep...</td>\n",
       "      <td>The National Sleep Foundation Sleep Health Saf...</td>\n",
       "      <td>sleepfoundation org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Peanut Butter Banana Bread with Reese s Peanut...</td>\n",
       "      <td>Is there a support group for banana bread addi...</td>\n",
       "      <td>laphemmephoodie 2011 02 peanut butter banana b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Safety tips for hot summer days USATODAY com s...</td>\n",
       "      <td>By Janice Lloyd USA TODAY Updated Heat is a ma...</td>\n",
       "      <td>usatoday news health story 2012 07 02 Summer h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>phoenixnewtimes 2008 03 20 news it took less t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>9 Timeless Nutrition Tips for Any Age 9 timele...</td>\n",
       "      <td>March 22nd 2010 1 55 am by Marc This guest pos...</td>\n",
       "      <td>marcandangel 2010 03 22 9 timeless nutrition t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NBA Offseason Betting Tips Personnel Changes A...</td>\n",
       "      <td>Posted by Craig Parsons on 8 9 2012 2 49 09 PM...</td>\n",
       "      <td>betonline sports betting basketball nba nba of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Breaking News Headlines Business Entertainment...</td>\n",
       "      <td>news covering all the latest breaking nation...</td>\n",
       "      <td>cbsnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Easy Healthy Recipes</td>\n",
       "      <td>Do you have delicious family recipes that have...</td>\n",
       "      <td>1001recipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   IBM Sees Holographic Calls Air Breathing Batte...   \n",
       "1   The Fully Electronic Futuristic Starting Gun T...   \n",
       "2   Fruits that Fight the Flu fruits that fight th...   \n",
       "3                 10 Foolproof Tips for Better Sleep    \n",
       "4   The 50 Coolest Jerseys You Didn t Know Existed...   \n",
       "5                           Genital Herpes Treatment    \n",
       "6                   fashion lane American Wild Child    \n",
       "7   Racing For Recovery by Dean Johnson racing for...   \n",
       "8                  Valet The Handbook 31 Days 31 days   \n",
       "9         Cookies and Cream Brownies How Sweet It Is    \n",
       "10  Business Financial News Breaking US Internatio...   \n",
       "11  A Tip of the Cap to The Greatest Iron Man of T...   \n",
       "12                     9 Foods That Trash Your Teeth    \n",
       "13                                                      \n",
       "14  French Onion Steaks with Red Wine Sauce french...   \n",
       "15  Izabel Goulart Swimsuit by Kikidoll 2012 Sport...   \n",
       "16                Liquid Mountaineering The Awesomer    \n",
       "17                                                      \n",
       "18                      Grilled Peaches Sugarcrafter    \n",
       "19  How to Make Your Home Healthier A Room by Room...   \n",
       "20  Olympic Soccer Babe Alex Morgan Medal Winning ...   \n",
       "21     BBC Food Recipes Blueberry and lemon traybake    \n",
       "22  Quit Smoking Counter Online counter that measu...   \n",
       "23        Original techniques to tie your shoe laces    \n",
       "24                                                      \n",
       "25   Best College Football Fan Sign Ever Alabama Fan    \n",
       "26                                Breaking News Blog    \n",
       "27                 The Alton Brown Flower Pot Smoker    \n",
       "28      Supermodels show off their bikini bods Humor    \n",
       "29  Genevieve Morton Swimsuit by Tyler Rose Swimwe...   \n",
       "30                   Homemade Bagels Tammy s Recipes    \n",
       "31     Whole Wheat Chocolate Chai Muffins Savvy Eats    \n",
       "32                           Ten ways to be Fabulous    \n",
       "33  Asian Orange Chicken Recipe Allrecipes com asi...   \n",
       "34  Chocolate Bread Pudding with Walnuts and Choco...   \n",
       "35            NerdsMagazine Everything About Android    \n",
       "36  Microwave Popcorn Minus the Ripoff microwave p...   \n",
       "37           Pogo Shoes CollegeHumor Video pogo shoes   \n",
       "38  Creamy Raspberry Orange Popsicles PETA org cre...   \n",
       "39  Doctors Strike Mutating Bacteria In Teen Acne ...   \n",
       "40                          The bottled water fad UK    \n",
       "41  canarygirl com I am a Pickle Ho And I think I ...   \n",
       "42  Photo 1 Festive Funky Holiday Nail Art DIYs fe...   \n",
       "43  11 Power Foods for Lower Cholesterol High Chol...   \n",
       "44  Alyssa Miller Swimsuit by Charlie by Matthew Z...   \n",
       "45                           Breaking News Headlines    \n",
       "46                                  Twenty1F twenty1f   \n",
       "47  Apple Dumplings II Recipe Allrecipes com apple...   \n",
       "48  300lbs American footballer Danous Estenor lift...   \n",
       "49  Pro Athletes Who Went Broke pro athletes who w...   \n",
       "50  Fashion Blog Baur Most Expensive Jeans in the ...   \n",
       "51       Best S mores Recipes Ever YummyMummyClub ca    \n",
       "52  National Sleep Foundation Information on Sleep...   \n",
       "53  Peanut Butter Banana Bread with Reese s Peanut...   \n",
       "54  Safety tips for hot summer days USATODAY com s...   \n",
       "55                                                      \n",
       "56  9 Timeless Nutrition Tips for Any Age 9 timele...   \n",
       "57  NBA Offseason Betting Tips Personnel Changes A...   \n",
       "58  Breaking News Headlines Business Entertainment...   \n",
       "59                              Easy Healthy Recipes    \n",
       "\n",
       "                                                 body  \\\n",
       "0   A sign stands outside the International Busine...   \n",
       "1   And that can be carried on a plane without the...   \n",
       "2   Apples The most popular source of antioxidants...   \n",
       "3   There was a period in my life when I had a lot...   \n",
       "4   Jersey sales is a curious business Whether you...   \n",
       "5   Genital herpes is caused by herpes simplex vir...   \n",
       "6   Our favorite summer holiday is just around the...   \n",
       "7   Racing For Recovery is the growing idea that d...   \n",
       "8   Resolutions are for suckers Instead of swearin...   \n",
       "9   More brownies It seems that I can t get throug...   \n",
       "10  Faced with a stream of financial scandals the ...   \n",
       "11  As you surely know by now Brett Favre s NFL re...   \n",
       "12  There are the 700 different types of germs in ...   \n",
       "13                                                      \n",
       "14  Really this is just an excuse to get drunk Or ...   \n",
       "15  TM 2012 Turner Broadcasting System Inc A Time ...   \n",
       "16  Link We re pretty skeptical about walking on w...   \n",
       "17  The annual Chap Olympiad described as a celebr...   \n",
       "18  June 6 2011 Print E mail Filed under grilled p...   \n",
       "19  Studies show one in three shower heads are con...   \n",
       "20  Olympic Soccer BabeMedal Winning Bikini Body T...   \n",
       "21   this fruity traybake is so good, you won't be...   \n",
       "22  Loading After You Quit Smoking The Healing Beg...   \n",
       "23  http www damascus online com guide p 4 8734 ie...   \n",
       "24                                                      \n",
       "25  Want a prime example of just how intertwined t...   \n",
       "26  Contact Empty List Empty List Empty List Katie...   \n",
       "27  Friends built the Alton Brown flower pot smoke...   \n",
       "28  May 1222 Miranda Kerr Irina Shayk Behati Prins...   \n",
       "29  Genevieve Morton 24 hails from Benoni South Af...   \n",
       "30  I m a very unskilled baker in fact I think I c...   \n",
       "31  I think I subconsciously sabotaged myself Two ...   \n",
       "32  One of my favorite bloggers Ashe Mischief over...   \n",
       "33   enjoy delicious citrus chicken marinated in l...   \n",
       "34  Toss bread cubes 1 2 cup chocolate chips and t...   \n",
       "35  If you are from your Windows default look woul...   \n",
       "36  May 6 2008 2 49 pm By MARK BITTMAN Somehow I v...   \n",
       "37  Drink Thief My room mate has this annoying hab...   \n",
       "38   creamy raspberry-orange popsicles are a refre...   \n",
       "39  Charles Bowman University of Pittsburgh A tiny...   \n",
       "40  Part 1 Introduction One of the most profitable...   \n",
       "41  Holy mother of mothers folks I don t know if y...   \n",
       "42  Festive Funky Holiday Nail Art DIYs Snowfall G...   \n",
       "43  Oils 6 image While butter and other solid fats...   \n",
       "44  Alyssa Miller 20 was born in Los Angeles Calif...   \n",
       "45  AMDB10K Where News Research Rewards News We Se...   \n",
       "46  Jul23 Francesca Lanzavecchia born in Pavia Ita...   \n",
       "47   whole apples are wrapped in homemade pastry, ...   \n",
       "48  By Mark DuellLast updated at 2 10 AM on 25th J...   \n",
       "49  rate or flagPin It By HypersapienWhat Happened...   \n",
       "50  08 11 2010 Undoubtedly the most famous of Levi...   \n",
       "51  Nothing says summer fun like cooking marshmall...   \n",
       "52  The National Sleep Foundation Sleep Health Saf...   \n",
       "53  Is there a support group for banana bread addi...   \n",
       "54  By Janice Lloyd USA TODAY Updated Heat is a ma...   \n",
       "55                                                      \n",
       "56  March 22nd 2010 1 55 am by Marc This guest pos...   \n",
       "57  Posted by Craig Parsons on 8 9 2012 2 49 09 PM...   \n",
       "58    news covering all the latest breaking nation...   \n",
       "59  Do you have delicious family recipes that have...   \n",
       "\n",
       "                                                  url  \n",
       "0   bloomberg news 2010 12 23 ibm predicts hologra...  \n",
       "1   popsci technology article 2012 07 electronic f...  \n",
       "2   menshealth health flu fighting fruits cm mmc F...  \n",
       "3   dumblittleman 2007 12 10 foolproof tips for be...  \n",
       "4   bleacherreport articles 1205138 the 50 coolest...  \n",
       "5          conveniencemedical genital herpes home php  \n",
       "6   gofashionlane blogspot tw 2012 06 american wil...  \n",
       "7     insidershealth article racing for recovery 3471  \n",
       "8   valetmag the handbook features 31 days index p...  \n",
       "9   howsweeteats 2010 03 24 cookies and cream brow...  \n",
       "10                                            reuters  \n",
       "11  midwestsportsfans 2010 12 photo story the grea...  \n",
       "12  ivillage our dirty mouths 4 b 188305 iv NPA 1 ...  \n",
       "13  thedailygreen print this healthy eating eat sa...  \n",
       "14  phillyburbs blogs type a kitchen french onion ...  \n",
       "15  sportsillustrated cnn 2012 swimsuit models iza...  \n",
       "16            theawesomer liquid mountaineering 38622  \n",
       "17  guardian co uk fashion gallery 2012 jul 08 gen...  \n",
       "18            sugarcrafter 2011 06 06 grilled peaches  \n",
       "19  ivillage bathroom degrunge your shower head sh...  \n",
       "20  tmz 2012 12 20 olympic soccer alex morgan biki...  \n",
       "21  bbc co uk food recipes blueberry and lemon 090...  \n",
       "22                        quitcounter quitsmoking php  \n",
       "23  monicel info 2008 08 03 original techniques to...  \n",
       "24  blogs babble family kitchen 2011 04 06 ultimat...  \n",
       "25  midwestsportsfans 2010 10 early 2010 nominee f...  \n",
       "26                                   breakingnewsblog  \n",
       "27  naffziger blog 2008 07 05 the alton brown flow...  \n",
       "28  humor cool been wp supermodels show off their ...  \n",
       "29  sportsillustrated cnn 2011 swimsuit models gen...  \n",
       "30                      tammysrecipes homemade bagels  \n",
       "31        savvyeat whole wheat chocolate chai muffins  \n",
       "32  chicandcharming 2008 01 ten ways to be fabulou...  \n",
       "33  allrecipes Recipe Asian Orange Chicken Detail ...  \n",
       "34  epicurious articlesguides holidays valentinesd...  \n",
       "35                                      nerdsmagazine  \n",
       "36  bitten blogs nytimes 2008 05 06 microwave popc...  \n",
       "37                         collegehumor video 1806201  \n",
       "38  peta org living vegetarian living creamy raspb...  \n",
       "39  npr org blogs health 2012 10 15 162821580 doct...  \n",
       "40                  second opinions co uk bottle html  \n",
       "41                                   canarygirl p 302  \n",
       "42          refinery29 holiday nail art diy slideshow  \n",
       "43  everydayhealth high cholesterol pictures power...  \n",
       "44  sportsillustrated cnn 2011 swimsuit action aly...  \n",
       "45                              amdb10k breaking news  \n",
       "46                                           twenty1f  \n",
       "47  allrecipes Recipe Apple Dumplings II 2 Detail ...  \n",
       "48  dailymail co uk news article 2007972 300lbs Am...  \n",
       "49  hypersapien hubpages hubfc hub Pro Athletes Wh...  \n",
       "50  baur de content tunk categories jeans most exp...  \n",
       "51  yummymummyclub ca food recipes best smores rec...  \n",
       "52                                sleepfoundation org  \n",
       "53  laphemmephoodie 2011 02 peanut butter banana b...  \n",
       "54  usatoday news health story 2012 07 02 Summer h...  \n",
       "55  phoenixnewtimes 2008 03 20 news it took less t...  \n",
       "56  marcandangel 2010 03 22 9 timeless nutrition t...  \n",
       "57  betonline sports betting basketball nba nba of...  \n",
       "58                                            cbsnews  \n",
       "59                                         1001recipe  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ano_text_data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b19ce21f41f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_reduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'bbb\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mval_count_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-b19ce21f41f2>\u001b[0m in \u001b[0;36mval_count_stopwords\u001b[0;34m(data_)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtwit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtwit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "def val_count_stopwords(data_):\n",
    "    fea = ['title', 'body', 'url']\n",
    "    stop_words = stopwords.words('english')\n",
    "    for name in fea:\n",
    "        vocab = Counter()\n",
    "        count = 0\n",
    "        for twit in data_[name]:\n",
    "            for word in twit.split(' '):\n",
    "                vocab[word] += 1\n",
    "            count += 1\n",
    "        print(name, vocab.most_common(20), end= 'aaa\\n\\n')\n",
    "\n",
    "        vocab_reduced = Counter()\n",
    "        for w, c in vocab.items():\n",
    "            if not w in stop_words:\n",
    "                vocab_reduced[w]=c\n",
    "\n",
    "        print(name, vocab_reduced.most_common(20), end= 'bbb\\n\\n')\n",
    "val_count_stopwords(ano_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like it  :)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocessor(text):\n",
    "    \"\"\" Return a cleaned version of text\n",
    "    \"\"\"\n",
    "    # Remove HTML markup\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Save emoticons for later appending\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # Remove any non-word character and append the emoticons,\n",
    "    # removing the nose character for standarization. Convert to lower case\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "    \n",
    "    return text\n",
    "print(preprocessor('I like it :), |||<><>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'there,', 'I', 'am', 'loving', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n",
      "['Hi', 'there,', 'I', 'am', 'love', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Split a text into list of words\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "# Split a text into list of words and apply stemming technic\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "print(tokenizer('Hi there, I am loving this, like with a lot of love'))\n",
    "print(tokenizer_porter('Hi there, I am loving this, like with a lot of love'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5916,), (1479,), (5916,), (1479,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = ano_text_data['body']\n",
    "b = main_data['label']\n",
    "A_train, A_test, b_train, b_test = train_test_split(A, b, test_size=0.2, random_state=102)\n",
    "A_train.shape, A_test.shape, b_train.shape, b_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(preprocessor=<function preprocessor at 0x7f49d0f5bd30>,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                 tokenizer=<function tokenizer_porter at 0x7f49d0f5b700>)),\n",
       "                ('clf', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words,\n",
    "                        tokenizer=tokenizer_porter,\n",
    "                        preprocessor=preprocessor)\n",
    "\n",
    "# A pipeline is what chains several steps together, once the initial exploration is done. \n",
    "# For example, some codes are meant to transform features — normalise numericals, or turn text into vectors, \n",
    "# or fill up missing data, they are transformers; other codes are meant to predict variables by fitting an algorithm,\n",
    "# they are estimators. Pipeline chains all these together which can then be applied to training data\n",
    "clf = Pipeline([('vect', tfidf),\n",
    "                ('clf', LogisticRegression(random_state=0))])\n",
    "clf.fit(A_train, b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7809330628803245\n",
      "confusion matrix:\n",
      " [[645  98]\n",
      " [226 510]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now apply those above metrics to evaluate your model\n",
    "# Your code here\n",
    "predictions = clf.predict(A_test)\n",
    "print('accuracy:',accuracy_score(b_test,predictions))\n",
    "print('confusion matrix:\\n',confusion_matrix(b_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc_auc_accu 85.49478099947333\n"
     ]
    }
   ],
   "source": [
    "print(\"Roc_auc_accu\", roc_auc_score(b_test, clf.predict_proba(A_test)[:, 1]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
